{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain_experimental\n",
      "  Using cached langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-google-community\n",
      "  Using cached langchain_google_community-2.0.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.0.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting langchain-huggingface==0.0.3\n",
      "  Using cached langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting langchain-qdrant\n",
      "  Using cached langchain_qdrant-0.1.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-google-vertexai\n",
      "  Using cached langchain_google_vertexai-2.0.5-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from langchain-huggingface==0.0.3)\n",
      "  Using cached huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langchain-core\n",
      "  Using cached langchain_core-0.2.41-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface==0.0.3)\n",
      "  Using cached sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain-huggingface==0.0.3)\n",
      "  Using cached tokenizers-0.20.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting transformers>=4.39.0 (from langchain-huggingface==0.0.3)\n",
      "  Using cached transformers-4.45.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-community)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Using cached SQLAlchemy-2.0.36-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.7 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.10.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.6 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.3 (from langchain-community)\n",
      "  Using cached langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "  Using cached langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.16 (from langchain-community)\n",
      "  Using cached langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.112 (from langchain-community)\n",
      "  Using cached langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain-community)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (114 kB)\n",
      "Collecting requests<3,>=2 (from langchain-community)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-community)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain-core)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-experimental to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain_experimental\n",
      "  Using cached langchain_experimental-0.3.1.post1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.3.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.3.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "  Using cached langchain_experimental-0.0.65-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting google-api-core<3.0.0,>=2.17.1 (from langchain-google-community)\n",
      "  Using cached google_api_core-2.21.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting google-api-python-client<3.0.0,>=2.122.0 (from langchain-google-community)\n",
      "  Using cached google_api_python_client-2.149.0-py2.py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-cloud-core<3.0.0,>=2.4.1 (from langchain-google-community)\n",
      "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting grpcio<2.0.0,>=1.62.0 (from langchain-google-community)\n",
      "  Using cached grpcio-1.67.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-google-community to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-community\n",
      "  Using cached langchain_google_community-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached langchain_google_community-1.0.8-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-community)\n",
      "  Using cached tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting google-generativeai<0.9.0,>=0.8.0 (from langchain-google-genai)\n",
      "  Using cached google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-google-genai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting google-generativeai<0.8.0,>=0.7.0 (from langchain-google-genai)\n",
      "  Using cached google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting langchain-google-genai\n",
      "  Using cached langchain_google_genai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-openai\n",
      "  Using cached langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "  Using cached langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai)\n",
      "  Using cached openai-1.52.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
      "  Using cached tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting qdrant-client<2.0.0,>=1.10.1 (from langchain-qdrant)\n",
      "  Using cached qdrant_client-1.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-aiplatform<2.0.0,>=1.69.0 (from langchain-google-vertexai)\n",
      "  Using cached google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting google-cloud-storage<3.0.0,>=2.18.0 (from langchain-google-vertexai)\n",
      "  Using cached google_cloud_storage-2.18.2-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting httpx<0.28.0,>=0.27.0 (from langchain-google-vertexai)\n",
      "  Using cached httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-google-vertexai)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "INFO: pip is looking at multiple versions of langchain-google-vertexai to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting langchain-google-vertexai\n",
      "  Using cached langchain_google_vertexai-2.0.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "  Using cached langchain_google_vertexai-1.0.10-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.0 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.15.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (58 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.23.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached protobuf-5.28.2-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached proto_plus-1.24.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached google_auth-2.35.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httplib2<1.dev0,>=0.19.0 (from google-api-python-client<3.0.0,>=2.122.0->langchain-google-community)\n",
      "  Using cached httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client<3.0.0,>=2.122.0->langchain-google-community)\n",
      "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client<3.0.0,>=2.122.0->langchain-google-community)\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 (from google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Using cached google_cloud_bigquery-3.26.0-py2.py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting google-cloud-resource-manager<3.0.0dev,>=1.3.3 (from google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Using cached google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting shapely<3.0.0dev (from google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Using cached shapely-2.0.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.0 kB)\n",
      "Collecting docstring-parser<1 (from google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Using cached docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai)\n",
      "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3.0.0,>=2.18.0->langchain-google-vertexai)\n",
      "  Using cached google_crc32c-1.6.0-cp311-cp311-macosx_12_0_arm64.whl.metadata (2.3 kB)\n",
      "Collecting google-ai-generativelanguage==0.6.6 (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Using cached google_ai_generativelanguage-0.6.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting tqdm (from google-generativeai<0.8.0,>=0.7.0->langchain-google-genai)\n",
      "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 (from google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Collecting anyio (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai)\n",
      "  Using cached anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai)\n",
      "  Using cached httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio (from httpx<0.28.0,>=0.27.0->langchain-google-vertexai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.28.0,>=0.27.0->langchain-google-vertexai)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.3)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.23.0->langchain-huggingface==0.0.3)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.16->langchain-community)\n",
      "  Using cached langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.112->langchain-community)\n",
      "  Using cached orjson-3.10.7-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.112->langchain-community)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai)\n",
      "  Using cached jiter-0.6.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1->langchain-core)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1->langchain-core)\n",
      "  Using cached pydantic_core-2.23.4-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant)\n",
      "  Using cached grpcio_tools-1.67.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant)\n",
      "  Using cached portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting urllib3<3,>=1.26.14 (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain-community)\n",
      "  Using cached charset_normalizer-3.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached torch-2.5.0-cp311-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached pillow-11.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai)\n",
      "  Using cached regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.39.0->langchain-huggingface==0.0.3)\n",
      "  Using cached safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Using cached grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached cachetools-5.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting python-dateutil<3.0dev,>=2.7.3 (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting grpc-google-iam-v1<1.0.0dev,>=0.12.4 (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Using cached grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client<2.0.0,>=1.10.1->langchain-qdrant)\n",
      "  Using cached grpcio_tools-1.66.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.66.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.66.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.65.5-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.65.4-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.65.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.65.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_tools-1.64.3-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.64.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.64.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.63.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "  Using cached grpcio_tools-1.63.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (5.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached grpcio_tools-1.62.3-cp311-cp311-macosx_10_10_universal2.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant) (75.1.0)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1.dev0,>=0.19.0->google-api-python-client<3.0.0,>=2.122.0->langchain-google-community)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant)\n",
      "  Using cached h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached networkx-3.4.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.dev0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Using cached grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Using cached grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant)\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client<2.0.0,>=1.10.1->langchain-qdrant)\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=2.17.1->langchain-google-community)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform<2.0.0,>=1.69.0->langchain-google-vertexai)\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface==0.0.3)\n",
      "  Using cached MarkupSafe-3.0.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Using cached langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Using cached langchain_community-0.2.17-py3-none-any.whl (2.3 MB)\n",
      "Using cached langchain_core-0.2.41-py3-none-any.whl (397 kB)\n",
      "Using cached langchain_experimental-0.0.65-py3-none-any.whl (207 kB)\n",
      "Using cached langchain_google_community-1.0.8-py3-none-any.whl (75 kB)\n",
      "Using cached langchain_google_genai-1.0.10-py3-none-any.whl (39 kB)\n",
      "Using cached langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n",
      "Using cached langchain_qdrant-0.1.4-py3-none-any.whl (23 kB)\n",
      "Using cached langchain_google_vertexai-1.0.10-py3-none-any.whl (86 kB)\n",
      "Using cached aiohttp-3.10.10-cp311-cp311-macosx_11_0_arm64.whl (390 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached google_api_core-2.21.0-py3-none-any.whl (156 kB)\n",
      "Using cached google_api_python_client-2.149.0-py2.py3-none-any.whl (12.3 MB)\n",
      "Using cached google_cloud_aiplatform-1.70.0-py2.py3-none-any.whl (5.3 MB)\n",
      "Using cached google_cloud_storage-2.18.2-py2.py3-none-any.whl (130 kB)\n",
      "Using cached google_generativeai-0.7.2-py3-none-any.whl (164 kB)\n",
      "Using cached google_ai_generativelanguage-0.6.6-py3-none-any.whl (718 kB)\n",
      "Using cached grpcio-1.67.0-cp311-cp311-macosx_10_9_universal2.whl (11.0 MB)\n",
      "Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Using cached httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain-0.2.16-py3-none-any.whl (1.0 MB)\n",
      "Using cached langsmith-0.1.135-py3-none-any.whl (295 kB)\n",
      "Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)\n",
      "Using cached openai-1.52.0-py3-none-any.whl (386 kB)\n",
      "Downloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached qdrant_client-1.12.0-py3-none-any.whl (266 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sentence_transformers-3.2.0-py3-none-any.whl (255 kB)\n",
      "Using cached SQLAlchemy-2.0.36-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)\n",
      "Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached tiktoken-0.8.0-cp311-cp311-macosx_11_0_arm64.whl (982 kB)\n",
      "Using cached tokenizers-0.20.1-cp311-cp311-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Using cached aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Using cached charset_normalizer-3.4.0-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)\n",
      "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Using cached google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
      "Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Using cached google_cloud_bigquery-3.26.0-py2.py3-none-any.whl (239 kB)\n",
      "Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
      "Using cached google_cloud_resource_manager-1.12.5-py2.py3-none-any.whl (341 kB)\n",
      "Using cached google_crc32c-1.6.0-cp311-cp311-macosx_12_0_arm64.whl (30 kB)\n",
      "Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
      "Using cached grpcio_tools-1.62.3-cp311-cp311-macosx_10_10_universal2.whl (5.1 MB)\n",
      "Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached jiter-0.6.1-cp311-cp311-macosx_11_0_arm64.whl (302 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached langchain_text_splitters-0.2.4-py3-none-any.whl (25 kB)\n",
      "Using cached marshmallow-3.23.0-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.1.0-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Using cached orjson-3.10.7-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (251 kB)\n",
      "Using cached portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Using cached proto_plus-1.24.0-py3-none-any.whl (50 kB)\n",
      "Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "Using cached regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached safetensors-0.4.5-cp311-cp311-macosx_11_0_arm64.whl (381 kB)\n",
      "Using cached shapely-2.0.6-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached torch-2.5.0-cp311-none-macosx_11_0_arm64.whl (64.3 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Using cached yarl-1.15.4-cp311-cp311-macosx_11_0_arm64.whl (86 kB)\n",
      "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Using cached pillow-11.0.0-cp311-cp311-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Using cached scikit_learn-1.5.2-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB)\n",
      "Using cached scipy-1.14.1-cp311-cp311-macosx_14_0_arm64.whl (23.1 MB)\n",
      "Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
      "Using cached grpc_google_iam_v1-0.13.1-py2.py3-none-any.whl (24 kB)\n",
      "Using cached grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached propcache-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (45 kB)\n",
      "Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.4.1-py3-none-any.whl (1.7 MB)\n",
      "Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached MarkupSafe-3.0.1-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: mpmath, urllib3, uritemplate, typing-extensions, tqdm, threadpoolctl, tenacity, sympy, sniffio, six, safetensors, regex, PyYAML, pyparsing, pyasn1, protobuf, propcache, portalocker, Pillow, packaging, orjson, numpy, networkx, mypy-extensions, multidict, MarkupSafe, jsonpointer, joblib, jiter, idna, hyperframe, httpx-sse, hpack, h11, grpcio, google-crc32c, fsspec, frozenlist, filelock, docstring-parser, distro, charset-normalizer, certifi, cachetools, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, shapely, scipy, rsa, requests, python-dateutil, pydantic-core, pyasn1-modules, proto-plus, marshmallow, jsonpatch, jinja2, httplib2, httpcore, h2, grpcio-tools, googleapis-common-protos, google-resumable-media, anyio, aiosignal, torch, tiktoken, scikit-learn, requests-toolbelt, pydantic, huggingface-hub, httpx, grpcio-status, google-auth, dataclasses-json, aiohttp, tokenizers, openai, langsmith, grpc-google-iam-v1, google-auth-httplib2, google-api-core, transformers, qdrant-client, langchain-core, google-cloud-core, google-api-python-client, sentence-transformers, langchain-text-splitters, langchain-qdrant, langchain-openai, google-cloud-storage, google-cloud-resource-manager, google-cloud-bigquery, google-ai-generativelanguage, langchain-huggingface, langchain, google-generativeai, google-cloud-aiplatform, langchain-google-vertexai, langchain-google-genai, langchain-community, langchain-google-community, langchain_experimental\n",
      "Successfully installed MarkupSafe-3.0.1 Pillow-11.0.0 PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 attrs-24.2.0 cachetools-5.5.0 certifi-2024.8.30 charset-normalizer-3.4.0 dataclasses-json-0.6.7 distro-1.9.0 docstring-parser-0.16 filelock-3.16.1 frozenlist-1.4.1 fsspec-2024.9.0 google-ai-generativelanguage-0.6.6 google-api-core-2.21.0 google-api-python-client-2.149.0 google-auth-2.35.0 google-auth-httplib2-0.2.0 google-cloud-aiplatform-1.70.0 google-cloud-bigquery-3.26.0 google-cloud-core-2.4.1 google-cloud-resource-manager-1.12.5 google-cloud-storage-2.18.2 google-crc32c-1.6.0 google-generativeai-0.7.2 google-resumable-media-2.7.2 googleapis-common-protos-1.65.0 grpc-google-iam-v1-0.13.1 grpcio-1.67.0 grpcio-status-1.62.3 grpcio-tools-1.62.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.6 httplib2-0.22.0 httpx-0.27.2 httpx-sse-0.4.0 huggingface-hub-0.25.2 hyperframe-6.0.1 idna-3.10 jinja2-3.1.4 jiter-0.6.1 joblib-1.4.2 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.16 langchain-community-0.2.17 langchain-core-0.2.41 langchain-google-community-1.0.8 langchain-google-genai-1.0.10 langchain-google-vertexai-1.0.10 langchain-huggingface-0.0.3 langchain-openai-0.1.25 langchain-qdrant-0.1.4 langchain-text-splitters-0.2.4 langchain_experimental-0.0.65 langsmith-0.1.135 marshmallow-3.23.0 mpmath-1.3.0 multidict-6.1.0 mypy-extensions-1.0.0 networkx-3.4.1 numpy-1.26.4 openai-1.52.0 orjson-3.10.7 packaging-24.1 portalocker-2.10.1 propcache-0.2.0 proto-plus-1.24.0 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-2.9.2 pydantic-core-2.23.4 pyparsing-3.2.0 python-dateutil-2.9.0.post0 qdrant-client-1.12.0 regex-2024.9.11 requests-2.32.3 requests-toolbelt-1.0.0 rsa-4.9 safetensors-0.4.5 scikit-learn-1.5.2 scipy-1.14.1 sentence-transformers-3.2.0 shapely-2.0.6 six-1.16.0 sniffio-1.3.1 sympy-1.13.1 tenacity-8.3.0 threadpoolctl-3.5.0 tiktoken-0.8.0 tokenizers-0.20.1 torch-2.5.0 tqdm-4.66.5 transformers-4.45.2 typing-extensions-4.12.2 typing-inspect-0.9.0 uritemplate-4.1.1 urllib3-2.2.3 yarl-1.15.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting docx2txt\n",
      "  Using cached docx2txt-0.8-py3-none-any.whl\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: google-cloud-aiplatform in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (1.70.0)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.21.0)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (4.25.5)\n",
      "Requirement already satisfied: packaging>=14.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (24.1)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (3.26.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.0.6)\n",
      "Requirement already satisfied: pydantic<3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (2.9.2)\n",
      "Requirement already satisfied: docstring-parser<1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-aiplatform) (0.16)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.67.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (4.9)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=2.4.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=2.0.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.7.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (2.9.0.post0)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform) (1.6.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pydantic<3->google-cloud-aiplatform) (4.12.2)\n",
      "Requirement already satisfied: numpy<3,>=1.14 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from shapely<3.0.0dev->google-cloud-aiplatform) (1.26.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting google-cloud-discoveryengine\n",
      "  Using cached google_cloud_discoveryengine-0.12.3-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2.21.0)\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-discoveryengine) (2.35.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-discoveryengine) (1.24.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-cloud-discoveryengine) (4.25.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2.32.3)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.67.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (1.62.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1->google-cloud-discoveryengine) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-discoveryengine) (2024.8.30)\n",
      "Using cached google_cloud_discoveryengine-0.12.3-py3-none-any.whl (2.5 MB)\n",
      "Installing collected packages: google-cloud-discoveryengine\n",
      "Successfully installed google-cloud-discoveryengine-0.12.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from nltk) (2024.9.11)\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from nltk) (4.66.5)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Installing collected packages: click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting openpyxl\n",
      "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting pymupdf\n",
      "  Using cached PyMuPDF-1.24.11-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
      "Using cached PyMuPDF-1.24.11-cp38-abi3-macosx_11_0_arm64.whl (18.2 MB)\n",
      "Installing collected packages: pymupdf\n",
      "Successfully installed pymupdf-1.24.11\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting ragas==0.1.20\n",
      "  Using cached ragas-0.1.20-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from ragas==0.1.20) (1.26.4)\n",
      "Collecting datasets (from ragas==0.1.20)\n",
      "  Using cached datasets-3.0.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: tiktoken in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from ragas==0.1.20) (0.8.0)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from ragas==0.1.20) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from ragas==0.1.20) (0.2.41)\n",
      "Requirement already satisfied: langchain-community in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from ragas==0.1.20) (0.2.17)\n",
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from ragas==0.1.20) (0.1.25)\n",
      "Requirement already satisfied: openai>1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from ragas==0.1.20) (1.52.0)\n",
      "Collecting pysbd>=0.3.4 (from ragas==0.1.20)\n",
      "  Using cached pysbd-0.3.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting nest-asyncio (from ragas==0.1.20)\n",
      "  Downloading nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting appdirs (from ragas==0.1.20)\n",
      "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-core<0.3->ragas==0.1.20) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-core<0.3->ragas==0.1.20) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-core<0.3->ragas==0.1.20) (0.1.135)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-core<0.3->ragas==0.1.20) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-core<0.3->ragas==0.1.20) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-core<0.3->ragas==0.1.20) (8.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-core<0.3->ragas==0.1.20) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from openai>1->ragas==0.1.20) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from openai>1->ragas==0.1.20) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from openai>1->ragas==0.1.20) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from openai>1->ragas==0.1.20) (0.6.1)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from openai>1->ragas==0.1.20) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from openai>1->ragas==0.1.20) (4.66.5)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from datasets->ragas==0.1.20) (3.16.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets->ragas==0.1.20)\n",
      "  Using cached pyarrow-17.0.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->ragas==0.1.20)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets->ragas==0.1.20)\n",
      "  Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl.metadata (89 kB)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from datasets->ragas==0.1.20) (2.32.3)\n",
      "Collecting xxhash (from datasets->ragas==0.1.20)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets->ragas==0.1.20)\n",
      "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.6.1,>=2023.1.0 (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->ragas==0.1.20)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from datasets->ragas==0.1.20) (3.10.10)\n",
      "Requirement already satisfied: huggingface-hub>=0.22.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from datasets->ragas==0.1.20) (0.25.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain->ragas==0.1.20) (2.0.36)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain->ragas==0.1.20) (0.2.4)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langchain-community->ragas==0.1.20) (0.6.7)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from tiktoken->ragas==0.1.20) (2024.9.11)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.20) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.20) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.20) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.20) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.20) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from aiohttp->datasets->ragas==0.1.20) (1.15.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.1.20) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.20) (3.23.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.20) (0.9.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.20) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.1.20) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.1.20) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3->ragas==0.1.20) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3->ragas==0.1.20) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3->ragas==0.1.20) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3->ragas==0.1.20) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3->ragas==0.1.20) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas==0.1.20) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from requests>=2.32.2->datasets->ragas==0.1.20) (2.2.3)\n",
      "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting multiprocess (from datasets->ragas==0.1.20)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from pandas->datasets->ragas==0.1.20) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets->ragas==0.1.20)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets->ragas==0.1.20)\n",
      "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.1.20) (1.16.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas==0.1.20) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets->ragas==0.1.20) (0.2.0)\n",
      "Using cached ragas-0.1.20-py3-none-any.whl (190 kB)\n",
      "Using cached pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
      "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached datasets-3.0.1-py3-none-any.whl (471 kB)\n",
      "Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached pyarrow-17.0.0-cp311-cp311-macosx_11_0_arm64.whl (27.2 MB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Using cached pandas-2.2.3-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Using cached xxhash-3.5.0-cp311-cp311-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, appdirs, xxhash, tzdata, pysbd, pyarrow, nest-asyncio, fsspec, dill, pandas, multiprocess, datasets, ragas\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.9.0\n",
      "    Uninstalling fsspec-2024.9.0:\n",
      "      Successfully uninstalled fsspec-2024.9.0\n",
      "Successfully installed appdirs-1.4.4 datasets-3.0.1 dill-0.3.8 fsspec-2024.6.1 multiprocess-0.70.16 nest-asyncio-1.6.0 pandas-2.2.3 pyarrow-17.0.0 pysbd-0.3.4 pytz-2024.2 ragas-0.1.20 tzdata-2024.2 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tqdm in /opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "No broken requirements found.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# # Installs\n",
    "%pip install -U langchain-community langchain-core==0.2.40 langchain_experimental langchain-google-community langchain-google-genai langchain-huggingface==0.0.3 langchain-openai langchain-qdrant langchain-google-vertexai\n",
    "%pip install -U docx2txt\n",
    "%pip install -U google-cloud-aiplatform\n",
    "%pip install -U google-cloud-discoveryengine\n",
    "%pip install -U nltk\n",
    "%pip install -U openpyxl\n",
    "%pip install -U pymupdf\n",
    "%pip install -U python-dotenv\n",
    "%pip install -U ragas==0.1.20\n",
    "%pip install -U tqdm\n",
    "\n",
    "# Verify installed packages have compatible dependencies\n",
    "%pip check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "virtual-assist-poc-434617\n",
      "us-central1\n",
      "us\n",
      "virtual-assist-poc-docs_1727390753315\n"
     ]
    }
   ],
   "source": [
    "# Get environment variables\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import uuid\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "PROJECT_ID = os.environ['PROJECT_ID']\n",
    "print(PROJECT_ID)\n",
    "REGION = os.environ['REGION']\n",
    "print(REGION)\n",
    "LOCATION_ID = os.environ['LOCATION_ID']\n",
    "print(LOCATION_ID)\n",
    "DATA_STORE_ID = os.environ['DATA_STORE_ID']\n",
    "print(DATA_STORE_ID)\n",
    "\n",
    "LANGCHAIN_PROJECT=os.environ['LANGCHAIN_PROJECT'] + f\" - {uuid.uuid4().hex[0:8]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/david/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download punkt_tab module that is used for sentence tokenizaiton\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vertex AI\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(\n",
    "    project=os.environ['PROJECT_ID'], \n",
    "    location=os.environ['REGION'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'file_path': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'page': 0, 'total_pages': 134, 'format': 'PDF 1.5', 'title': '', 'author': 'PTN Consulting', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word 2013', 'producer': 'Microsoft Word 2013', 'creationDate': \"D:20170421101839-07'00'\", 'modDate': \"D:20170421103401-07'00'\", 'trapped': ''}\n"
     ]
    }
   ],
   "source": [
    "# Load the docs\n",
    "\n",
    "# TODO - add TextLoader refernece\n",
    "# TODO - add CSVLoader reference\n",
    "# https://python.langchain.com/docs/integrations/document_loaders/pymupdf/\n",
    "# https://python.langchain.com/docs/integrations/document_loaders/microsoft_word/\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "def process_file(path: str):\n",
    "\n",
    "    docs = None\n",
    "\n",
    "    # Select the right loader\n",
    "    if 'txt' in path.lower():\n",
    "        loader = TextLoader(path)\n",
    "    elif 'pdf' in path.lower():\n",
    "        loader = PyMuPDFLoader(path)\n",
    "    elif 'docx' in path.lower():\n",
    "        loader = Docx2txtLoader(path)\n",
    "    else:\n",
    "        print(f'No document loader found for {path}')\n",
    "\n",
    "    docs = loader.load()\n",
    "\n",
    "    return docs\n",
    "\n",
    "#####\n",
    "\n",
    "def test_process_file():\n",
    "    doc = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "    print(doc[0].metadata)\n",
    "\n",
    "test_process_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings using Hugging Face \n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "def create_embeddings_opensource(model: str) -> HuggingFaceEmbeddings:\n",
    "\n",
    "    # Initialize the OpenAIEmbeddings class\n",
    "    embeddings = HuggingFaceEmbeddings(model=model)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.0131338806822896, -0.0037410028744488955, 0.04308881610631943, -0.043627090752124786, -0.03259247913956642, 0.013968205079436302, -0.02541998028755188, -0.019889216870069504, -0.01629623956978321, 0.0030984384939074516, -0.000914224365260452, 0.010550166480243206, 0.0035929775331169367, 0.004100973252207041, -0.005779714789241552, -0.0023313984274864197, 0.051297493278980255, -0.009197752922773361, 0.005379373673349619, 0.005295268259942532, -0.013833636417984962, 0.0024255963508039713, 0.0038419291377067566, -0.0010529981227591634, -0.01407585944980383, 0.018059086054563522, 0.010563623160123825, -0.012158258818089962, -0.021759718656539917, -0.021719347685575485, 0.03646804764866829, 0.016417350620031357, -0.009554360061883926, -0.008464355021715164, -0.012158258818089962, 0.022540215402841568, 0.00017956476949620992, -0.009863867424428463, 0.02264786884188652, -0.00040980297490023077, 0.009137197397649288, 0.003249828005209565, -0.0010302896844223142, 0.004935297649353743, -0.006862991023808718, 0.00381165137514472, -0.009426519274711609, -0.025137385353446007, -0.013645240105688572, 0.007798241451382637, 0.023347625508904457, -0.020158354192972183, -0.03536458685994148, -0.0010790707310661674, -0.014371910132467747, -0.007401264738291502, 0.0016779003199189901, 0.02575640007853508, 0.0056182327680289745, -0.01504475250840187, 0.011270107701420784, 0.01605401560664177, -0.019633537158370018, -0.004151436500251293, -0.026119735091924667, 0.02342836745083332, 0.002534933155402541, 0.009231395088136196, -0.004649339709430933, 0.0035256934352219105, 0.019996872171759605, 0.030950743705034256, -0.021154159680008888, -0.01906834915280342, 0.03832509368658066, -0.005143878981471062, -0.01505820918828249, -0.011653627268970013, 0.01723821833729744, 0.01801871508359909, 0.02170589007437229, -0.01355777122080326, 0.004703167360275984, -0.001900779316201806, 0.009406334720551968, 0.012461038306355476, -0.01412968710064888, 0.024787507951259613, -0.002903314307332039, -0.01301276870071888, -0.0013742803130298853, 0.009137197397649288, 0.021652063354849815, 0.02718282677233219, -0.004518135450780392, 0.027128998190164566, -0.0003170768904965371, 0.017265131697058678, -0.01663265936076641, -0.009090098552405834, -0.023616762831807137, -0.008861332200467587, -0.023980097845196724, -0.02224416472017765, -0.009204481728374958, -0.020037241280078888, -0.012743632309138775, -0.008706578984856606, 0.022674784064292908, -0.018570445477962494, -0.031192965805530548, 0.0299549363553524, -0.004773815628141165, -0.04849846661090851, 0.020427489653229713, -0.01419697143137455, 0.006765428464859724, 0.02329379878938198, -0.03076234646141529, -0.003508872352540493, 0.021894287317991257, 0.014170057140290737, 0.012938756495714188, -0.015206234529614449, 0.010415597818791866, 0.016740314662456512, -0.015865620225667953, -0.005806628614664078, -0.006597218103706837, -0.01179492473602295, 0.0027132362592965364, 0.017076736316084862, 0.037033237516880035, 0.021584779024124146, -0.02224416472017765, 0.01010609045624733, -0.002102632075548172, -0.016847969964146614, -0.033076923340559006, 0.005359188187867403, 0.023078488186001778, 0.019660450518131256, -0.003915941808372736, -0.024922076612710953, -0.02206922508776188, 0.035203106701374054, 0.01842242106795311, 0.008955529890954494, 0.011404676362872124, -0.007421449758112431, 0.0005428995937108994, -0.019458597525954247, 0.004756994545459747, 0.019862303510308266, -0.003801558632403612, 0.006217062473297119, -0.013591413386166096, 0.016350066289305687, -0.013207892887294292, -0.030304813757538795, -0.014223884791135788, -0.03668335825204849, -0.0023566298186779022, -0.009641828946769238, -0.00204544048756361, 0.015219691209495068, 0.005924375727772713, -0.009561087936162949, -0.007219597231596708, 0.0039058492984622717, 0.02731739543378353, 0.028878388926386833, 0.013396289199590683, 0.005248169414699078, -0.015542655251920223, 0.015663767233490944, -0.0043297396041452885, 0.0006408822373487055, -0.010516524314880371, -0.007185955066233873, -0.023280341178178787, -0.013261720538139343, 0.027828754857182503, -0.0006871401565149426, -0.009460161440074444, 0.01900106482207775, 0.0005399559158831835, -0.014223884791135788, 0.009238123893737793, -0.007307066582143307, -0.007192683406174183, 0.012770545668900013, -0.002398682525381446, -0.01616167090833187, -0.6489428877830505, -0.0037107248790562153, 0.02799023687839508, 0.004397023934870958, 0.047206610441207886, 0.005022767465561628, 0.007031201384961605, -0.0007598911761306226, 0.0006429848726838827, -0.0012010233476758003, -0.006005116738379002, 0.00763003109022975, 0.006910089869052172, -0.0013768033822998405, 0.027357764542102814, -0.02240564674139023, 0.01294548436999321, -0.008006822317838669, -0.023347625508904457, -0.007737685926258564, -0.023576391860842705, 0.019149089232087135, -0.009143926203250885, 0.007966452278196812, 0.04109720513224602, 0.022607499733567238, 0.000494539039209485, -0.0005891574546694756, -0.03641422092914581, 0.02305157482624054, -0.013820179738104343, 0.017937973141670227, 0.021853916347026825, 0.018382050096988678, 0.05347749963402748, -0.009614915587008, -0.004074059892445803, 0.01392783410847187, -0.022540215402841568, 0.02007761225104332, -0.009877324104309082, -0.0013196117943152785, 0.006089222151786089, -0.007710772100836039, -0.005692245438694954, -0.004602240864187479, 0.028959129005670547, 0.010126275941729546, -0.0049453903920948505, 0.014654504135251045, 0.012178444303572178, 0.020239094272255898, -0.021880829706788063, 0.018341679126024246, 0.020911937579512596, -0.015690680593252182, 0.014344996772706509, -0.019485510885715485, 0.010947143658995628, 0.010200288146734238, 0.018368592485785484, 0.007919353432953358, -0.02305157482624054, -0.03159667178988457, -0.0035290576051920652, -0.0041648936457931995, -0.011909307911992073, 0.0021850550547242165, -0.0010521570220589638, -0.004444122780114412, 0.010630907490849495, 0.011700726114213467, -0.009291951544582844, 0.011599800549447536, 0.01703636534512043, 0.03932090103626251, 0.005527399014681578, -0.014466107822954655, -0.011700726114213467, 0.008814233355224133, -0.015300432220101357, -0.009016086347401142, 0.005113601218909025, 0.002957141725346446, 0.015636853873729706, 0.008706578984856606, -0.023239970207214355, -0.010947143658995628, 0.012494680471718311, -0.010079177096486092, 0.011229736730456352, 0.010859673842787743, -0.002793977502733469, -0.014762158505618572, -0.01889340952038765, -0.00029794295551255345, -0.028070978820323944, -0.03022407367825508, 0.011720911599695683, 0.0024255963508039713, -0.01909526251256466, 0.00713212788105011, -0.0001981730601983145, 0.022728610783815384, -0.011539244093000889, -0.009924422949552536, -0.014116230420768261, -0.001959653105586767, 0.029282094910740852, -0.010947143658995628, -0.009103555232286453, -0.00615314207971096, 0.015381173230707645, -0.011081711389124393, 0.03722163289785385, -0.011519059538841248, 9.764097740116995e-06, 0.002812480553984642, 0.0037410028744488955, -0.010852945037186146, 0.018543532118201256, -0.0056518749333918095, 0.026725294068455696, -0.020023785531520844, 0.005574497859925032, 0.00991769414395094, -0.02363021858036518, 0.00700428755953908, -0.017117107287049294, -0.015394630841910839, -0.013577956706285477, 0.004703167360275984, -0.01024065911769867, -0.022096138447523117, 0.012979126535356045, -0.030466295778751373, 0.005833541974425316, 0.010180102661252022, -0.008309601806104183, -0.006950460374355316, -0.026658009737730026, -0.004094244912266731, 0.0026358594186604023, 0.00031224085250869393, -0.0024541921447962523, -0.02139638364315033, 0.023536020889878273, 0.004965575877577066, 0.008625837042927742, -0.011700726114213467, -0.0131338806822896, -0.017453527078032494, -0.033346060663461685, 0.0005588795756921172, 0.009783126413822174, -0.004026960581541061, 0.006243975833058357, -0.039428554475307465, -0.01994304358959198, -0.01578487828373909, -0.01499092485755682, 0.03035864233970642, 0.0007485370151698589, 0.0015265108086168766, -0.013376103714108467, -0.020965764299035072, -0.007751142606139183, 0.03738311305642128, -0.015421544201672077, -0.028044063597917557, -0.0036838112864643335, -0.012023691087961197, 0.010805846191942692, 0.002841076347976923, -0.013315548188984394, -0.007757870946079493, 0.00884114671498537, -0.01741315796971321, -0.01040886901319027, 0.009164111688733101, 0.00663422467187047, -0.003009286941960454, -0.0038957565557211637, 0.00966874323785305, 0.016888340935111046, 0.011048069223761559, 0.009325593709945679, -0.0021043140441179276, -0.013470301404595375, 0.021248357370495796, -0.030466295778751373, 0.02450491487979889, -0.019714277237653732, 0.026927147060632706, 0.0008965622982941568, -0.021006135269999504, -0.0011648581130430102, 0.012662891298532486, 0.019391313195228577, 0.012972398661077023, 0.014304625801742077, 0.0014028761070221663, 0.01228609960526228, -0.0039697689935564995, 0.015879075974225998, -0.01764192432165146, -0.005783079192042351, -0.00867293681949377, -0.003979861736297607, 0.005349095910787582, -0.012319741770625114, -0.006365087348967791, 0.007784784771502018, -0.01595981791615486, 0.005574497859925032, 0.00226411409676075, -0.0032128216698765755, -0.008955529890954494, -0.014385366812348366, 0.020602429285645485, 0.005365916993469, 0.01308005303144455, 0.0037174534518271685, -0.003340661758556962, 0.009594730101525784, 0.009527445770800114, 0.01913563348352909, 0.039428554475307465, 0.006055579986423254, -0.0034584091044962406, -0.029631972312927246, 0.001434836070984602, 0.005527399014681578, 0.015219691209495068, 0.012824373319745064, 0.011122082360088825, -0.007172498386353254, -0.023105401545763016, 0.03116605244576931, 0.004417209420353174, 0.0068158917129039764, 0.011290293186903, 0.023805158212780952, -0.018462790176272392, 0.00755601841956377, 0.006358359009027481, 0.02494898997247219, 0.0021194531582295895, -0.000911701237782836, 0.011936221271753311, -0.011283564381301403, -0.007656944449990988, -0.016444263979792595, -0.004682981874793768, 0.004508043173700571, -0.032700132578611374, -0.019485510885715485, 0.03156975656747818, 0.029605058953166008, 0.035337675362825394, 0.018032172694802284, 0.03278087452054024, 0.0002897426893468946, -0.003862114390358329, 0.01734587363898754, 0.03245791047811508, 0.025379609316587448, -0.012736903503537178, -0.012319741770625114, 0.00243400689214468, 0.0030395647045224905, -0.0009411380742676556, 0.0011942950077354908, -0.011175910010933876, 0.03237716853618622, 0.00762330275028944, 0.002053851028904319, -0.005493756849318743, 0.019768105819821358, 0.0038452933076769114, -0.01357122790068388, -0.036656446754932404, 0.012043875642120838, 0.005039588548243046, 0.004602240864187479, -0.013053139671683311, -0.021719347685575485, -0.005648510530591011, -0.02105996198952198, 0.010334856808185577, 0.001349048689007759, -0.01083275955170393, -0.015461914241313934, -0.0020336657762527466, -0.006122864317148924, -0.005214527249336243, 0.038378920406103134, 0.001134580234065652, 0.01054343767464161, -0.019310573115944862, -0.01299931202083826, -0.036764100193977356, -0.020844653248786926, -0.019566252827644348, 0.004756994545459747, 0.011774739250540733, -0.018503161147236824, -0.046695251017808914, -0.004077423829585314, -0.021033048629760742, 0.002787248929962516, -0.02521812729537487, 0.009372692555189133, -0.03891719505190849, 0.019916130229830742, 0.025500720366835594, -0.014667960815131664, -0.0031825436744838953, 0.02646961435675621, -0.0012775592040270567, -0.009614915587008, -0.01893378049135208, -0.014143143780529499, 0.0008915159851312637, 0.06206296756863594, 0.0018974151462316513, 0.003288516541942954, -0.014721788465976715, -0.014869813807308674, 0.01419697143137455, -5.677106310031377e-05, -0.035310760140419006, 0.01585216261446476, 0.014102773740887642, 0.008269230835139751, 0.004918476566672325, -0.0050261314027011395, -0.0004861285269726068, -0.00939960591495037, 0.011081711389124393, -0.008585467003285885, -0.019149089232087135, -0.007159041240811348, -0.020239094272255898, -0.0056451465934515, 0.017857233062386513, 0.029416661709547043, 0.04451524093747139, 0.014950554817914963, 0.03291544318199158, 0.02011798322200775, 0.009298679418861866, 0.0283939428627491, -0.021517494693398476, -0.008040464483201504, -0.022607499733567238, 0.007730957120656967, 0.03870188444852829, -0.023751331493258476, -0.0025214762426912785, -0.004676253534853458, 0.006089222151786089, -0.001634165528230369, 0.01761500909924507, 0.024316517636179924, 0.03959003835916519, 0.017830319702625275, -0.023132316768169403, 0.013234807178378105, -0.009143926203250885, 0.0020033877808600664, -0.0053625525906682014, 0.024356888607144356, 0.0080471932888031, -0.014587219804525375, 0.007542561274021864, -0.01936439983546734, -0.030143331736326218, 0.036494962871074677, 0.005244805011898279, -0.01629623956978321, -0.004124523140490055, -0.002597171114757657, -0.0027771564200520515, -0.006442464422434568, -0.003623255528509617, 0.023334167897701263, -0.01784377545118332, -0.0299549363553524, -0.02971271239221096, -0.006317988503724337, -0.029147526249289513, -0.0009276812197640538, 0.009675471112132072, 0.01164689939469099, -0.016807598993182182, -0.014102773740887642, -0.011747825890779495, 0.003478594357147813, -0.014479564502835274, 0.031515929847955704, 0.014385366812348366, -0.00307152490131557, 0.031192965805530548, 0.004171621985733509, -0.03173124045133591, -0.006136320997029543, -0.016686487942934036, -0.007051386870443821, 0.0037376387044787407, 0.007387807592749596, 0.007838612422347069, -0.015690680593252182, 0.0010967327980324626, 0.011377762071788311, -0.0007985796546563506, 0.03089691512286663, -0.033076923340559006, 0.013308819383382797, -0.008538368158042431, -0.009083369746804237, 0.00529863266274333, -0.02599862404167652, -0.0019495603628456593, 0.0030261080246418715, -0.020642800256609917, 0.017332416027784348, -0.02541998028755188, 0.0008196059498004615, 0.004773815628141165, 0.02363021858036518, 0.005655238870531321, -0.011842023581266403, -0.025917882099747658, 0.03062777779996395, -0.015004381537437439, 0.017076736316084862, 0.0021615056321024895, 0.012864743359386921, 0.03700632229447365, 0.0050160386599600315, 0.02284972183406353, -0.01188239362090826, -0.004161529242992401, -0.012555235996842384, -0.022607499733567238, 0.013308819383382797, 0.023643676191568375, -0.02244601771235466, 0.015071665868163109, 0.0038419291377067566, 0.006146413739770651, -0.008874788880348206, 0.005419744178652763, -0.022768981754779816, 0.019283657893538475, -0.009702385403215885, -0.012077517807483673, -0.036764100193977356, -0.012622520327568054, -0.024451086297631264, 0.01511203683912754, -0.026442699134349823, -0.01277727447450161, 0.01589253358542919, -0.0024491457734256983, -0.006788978353142738, -0.0063482667319476604, 0.023105401545763016, -0.029362834990024567, -0.017386242747306824, -0.0008915159851312637, -0.02376478724181652, -0.0019562887027859688, 0.006032030563801527, -0.01228609960526228, -0.03372285142540932, -0.009117011912167072, -0.017184391617774963, -0.01208424661308527, 0.0059782033786177635, 0.00046005588956177235, 0.004356653429567814, 0.010455968789756298, 0.03380359336733818, 0.03272704780101776, 0.011545972898602486, 0.009964793920516968, -0.005147242918610573, -0.003244781633839011, -0.005396194756031036, -0.00371408904902637, -0.01949896849691868, 0.02454528398811817, -0.013954748399555683, -0.003142173169180751, 0.00023570503981318325, 0.008255774155259132, -0.011599800549447536, 0.020360205322504044, -0.010691463015973568, -0.01936439983546734, -0.02298429049551487, -0.03832509368658066, -0.00968219991773367, -0.0014567034086212516, 0.019122175872325897, 0.01512549351900816, -0.016202041879296303, -0.005113601218909025, 0.021436752751469612, -0.007542561274021864, 0.01433154009282589, -0.027155913412570953, 0.024195406585931778, -0.01784377545118332, 0.02879764698445797, -0.001846951898187399, -0.0034685018472373486, -0.005133786238729954, -0.004006775561720133, -0.0037611881271004677, -0.01517932116985321, 0.01485635619610548, 0.034261126071214676, 0.02217688038945198, -0.005382738076150417, 0.004225449170917273, -0.015071665868163109, -0.007421449758112431, -0.022742068395018578, -0.0067116012796759605, -0.005927740130573511, 0.012757088989019394, 0.012743632309138775, -0.012925299815833569, -0.02376478724181652, -0.02264786884188652, 0.01517932116985321, -0.006856262218207121, -0.028286287561058998, 0.013779808767139912, 0.025271954014897346, 0.016982538625597954, 0.006916818208992481, -0.011397947557270527, -0.0020336657762527466, 0.000637097517028451, 0.029389748349785805, 0.028851475566625595, 0.00551057793200016, 0.01392783410847187, -0.017736122012138367, -0.004965575877577066, -0.014493022114038467, 0.014533392153680325, 0.030789261683821678, -0.008780591189861298, -0.012985855340957642, 0.028959129005670547, -0.012965669855475426, -0.0478525385260582, -0.00991769414395094, 0.014291169121861458, 0.024316517636179924, 0.002255703555420041, 0.008168304339051247, -0.0035727922804653645, 0.0009680517832748592, 0.023065032437443733, -0.0007695633103139699, 0.006358359009027481, -0.009870595298707485, -0.010731833986938, -0.0019529246492311358, 0.02177317440509796, -0.0042489985935389996, 0.027236653491854668, -0.01741315796971321, 0.014802529476583004, -0.03525693342089653, -0.010469425469636917, -0.0036299838684499264, 0.0037510953843593597, -0.008329787291586399, 0.026577267795801163, 0.01505820918828249, 0.004104337655007839, 0.01213807426393032, 0.0025938067119568586, 0.01900106482207775, -0.00027418319950811565, 0.0023583120200783014, 0.032161857932806015, -0.008437441661953926, -0.004087516572326422, -0.00882096216082573, 0.004612333606928587, 0.026980973780155182, 0.005301996599882841, -0.009762940928339958, 0.03514927998185158, -0.013322276063263416, 0.014344996772706509, 0.013806723058223724, 0.013342461548745632, -0.03512236475944519, 0.00911028403788805, -0.00657366868108511, -0.003522329032421112, -0.00700428755953908, 0.001696403487585485, 0.014452651143074036, -0.019445139914751053, 0.007011015899479389, 0.013847093097865582, 0.018059086054563522, 0.011485417373478413, -0.0025702572893351316, 0.008013551123440266, 0.006324716843664646, -0.008800776675343513, -0.005460114683955908, 0.014250798150897026, 0.0068461699411273, 0.025056645274162292, -0.019929587841033936, 0.011566158384084702, -0.02463948354125023, -0.025446893647313118, 0.009251580573618412, -0.004545049276202917, -0.025460349395871162, -0.02593133971095085, 0.012319741770625114, 0.016726858913898468, 0.004444122780114412, -0.012736903503537178, -0.0036299838684499264, 0.00031602560193277895, 0.00041842376231215894, -0.009211210533976555, -0.045349568128585815, -0.009540903382003307, -0.012952213175594807, -0.01703636534512043, -0.0204544048756361, -0.026456156745553017, -0.011000970378518105, -0.013685611076653004, 0.03191963583230972, 0.0030681604985147715, -0.03261939063668251, -0.0149774681776762, -0.011007699184119701, 0.016619203612208366, -0.017386242747306824, -0.016336608678102493, -0.0031404912006109953, 0.006233883555978537, -0.025729486718773842, 0.03918633237481117, -0.006560212001204491, 0.023132316768169403, -0.029093697667121887, -0.0086056524887681, -0.012851286679506302, 0.008948802016675472, -0.0010033759754151106, 0.0037208176217973232, -0.008107748813927174, -0.013423202559351921, -0.024760594591498375, -0.0071052140556275845, -0.03062777779996395, 0.018610816448926926, 0.036521878093481064, -0.0028545332606881857, -0.023401452228426933, 0.004100973252207041, -0.044030796736478806, -0.014519935473799706, -0.010926958173513412, 0.013954748399555683, 0.001533239264972508, 0.010368498973548412, -0.006005116738379002, 0.014479564502835274, 0.02237873338162899, -0.008457627147436142, -0.02877073362469673, -0.011162452399730682, -0.007125399075448513, -0.013308819383382797, 0.0004415527218952775, 0.004178350325673819, -0.033480629324913025, -0.0015828614123165607, 0.01059726532548666, -0.002188419457525015, -0.0024726951960474253, -0.0036636260338127613, -0.006553483195602894, -0.002620720537379384, 0.014425737783312798, 0.015865620225667953, -0.0035156006924808025, -0.009877324104309082, -0.019781561568379402, -0.017534269019961357, 0.006738515105098486, 0.0031791795045137405, 0.006923546548932791, -0.021342555060982704, 0.013820179738104343, 0.03159667178988457, 0.0063482667319476604, -0.0017964887665584683, -0.026590725407004356, -0.010637635365128517, -0.004003411158919334, -5.956362201686716e-06, -0.0023885900154709816, 0.01774957776069641, -0.017009451985359192, 0.005887369625270367, -0.0018318130169063807, -0.01643080823123455, -0.024316517636179924, 0.0014861403033137321, -0.011572886258363724, -0.015475371852517128, 0.0159867312759161, -0.00946689024567604, -0.0037208176217973232, -0.009009357541799545, 0.004888198804110289, 0.00924485269933939, -0.01605401560664177, 7.353955152211711e-05, 0.01095387153327465, -0.025164300575852394, 0.006358359009027481, 0.004905019886791706, -0.022540215402841568, -0.015381173230707645, -0.0060959504917263985, -0.03536458685994148, 0.0012228908017277718, -0.030816175043582916, 0.003754459787160158, -0.0029251815285533667, -0.010065719485282898, 0.029282094910740852, -0.001449975068680942, -0.00897571537643671, -0.015556112863123417, 0.0054500219412148, 0.017588095739483833, 0.0010328128701075912, 0.25406521558761597, 0.005853727459907532, -0.023885900154709816, 0.01321462169289589, 0.017857233062386513, 0.015219691209495068, 0.019189460203051567, -0.004861284978687763, -0.005850363057106733, 0.023132316768169403, 0.028959129005670547, 0.011747825890779495, -0.013914377428591251, -0.001991613069549203, -0.026012081652879715, -0.03490705415606499, -0.0046325186267495155, 0.012043875642120838, -0.006963917054235935, -0.042308319360017776, 0.008955529890954494, 0.014210428111255169, 0.013019497506320477, 0.010577079840004444, 0.031892720609903336, 0.012716718018054962, -0.009036270901560783, -0.011048069223761559, 0.028636164963245392, 0.006392001174390316, -0.002097585704177618, 0.027061713859438896, -0.0006413027294911444, 0.009298679418861866, -0.0039327628910541534, 0.006311260163784027, 0.012487951666116714, -0.013026225380599499, 0.033319149166345596, -0.011175910010933876, -0.021423297002911568, -0.018705014139413834, -0.03143518790602684, 0.008780591189861298, 0.02318614348769188, 0.016942167654633522, -0.00409088097512722, -0.03248482197523117, -0.009823496453464031, 0.030062591657042503, -0.03186580911278725, -0.018543532118201256, 0.023549478501081467, 0.012313012965023518, -0.008713306859135628, 0.0008343243971467018, 0.029739627614617348, -0.014654504135251045, -0.008222131989896297, 0.01649809256196022, 0.026994431391358376, 0.019485510885715485, -0.007966452278196812, 0.02038712054491043, -0.011566158384084702, -0.02430306188762188, -0.02052168734371662, 0.01649809256196022, 0.017265131697058678, 0.02011798322200775, 0.008390342816710472, -0.008087563328444958, -0.009729298762977123, 0.01669994369149208, -0.02289009280502796, -0.006536662112921476, 0.026779120787978172, 0.01741315796971321, 0.011142267845571041, 0.007986637763679028, 0.015219691209495068, -0.008726763539016247, 0.016619203612208366, -0.027559617534279823, -0.012730174697935581, -0.015932904556393623, -0.006748607847839594, 0.0008797412156127393, -0.000206583586987108, -0.010496338829398155, 0.0006177533068694174, -0.016000188887119293, -0.01690179668366909, -0.026012081652879715, 0.03646804764866829, 0.007313794922083616, -0.014587219804525375, 0.01750735566020012, -0.013463573530316353, 0.018314765766263008, -0.01936439983546734, 0.059102460741996765, -0.007798241451382637, 0.013618326745927334, 0.001761164516210556, 0.011842023581266403, -0.034395694732666016, 0.008948802016675472, 0.0010412234114482999, -0.002538297325372696, 0.022472931072115898, -0.023038119077682495, 0.006667866371572018, -0.0046897102147340775, -0.014721788465976715, 0.002020208863541484, 0.028474682942032814, -0.02944357693195343, 0.00544329360127449, 0.009722569957375526, -0.0021648698020726442, -0.020266007632017136, 0.005759529769420624, 0.002745196223258972, 0.007374350912868977, 0.003338979557156563, -0.01565030962228775, -0.01220535859465599, 0.005332274828106165, -0.03907867893576622, 0.005426472518593073, 0.004541684873402119, 0.01519277784973383, -0.02025255188345909, -0.008847875520586967, 0.011236465536057949, -0.007905895821750164, -0.007589660584926605, -0.00558459060266614, 0.019216373562812805, -0.013349190354347229, -0.0036198911257088184, 0.011862209066748619, -0.017493898048996925, 0.006862991023808718, 0.016982538625597954, 0.0031993647571653128, -0.008612380363047123, -0.004962211474776268, -0.010852945037186146, -0.021813545376062393, -0.007414721418172121, 0.0033322512172162533, -0.00672505795955658, 0.046399202197790146, 0.014304625801742077, -0.017991801723837852, -0.011027884669601917, -0.003340661758556962, -0.0004680458805523813, -0.02667146548628807, -0.021046504378318787, 0.028555424883961678, 0.01652500592172146, -6.218533962965012e-05, -0.0036804471164941788, -0.1721399575471878, 0.0025467078667134047, 0.02416849322617054, -0.020467860624194145, 0.020091069862246513, 0.02490861900150776, -0.01412968710064888, -0.009675471112132072, -0.01379326544702053, -0.0005340685020200908, 0.012736903503537178, 0.010536709800362587, -0.012481223791837692, -0.00254334369674325, 0.01801871508359909, -0.007273424416780472, -0.0171036496758461, 0.026187019422650337, 0.019633537158370018, 0.029255179688334465, -0.004831007216125727, -0.0003019379510078579, 0.017332416027784348, -0.007273424416780472, 0.013423202559351921, 0.005779714789241552, -0.01320116501301527, -0.006772157270461321, 0.007650216110050678, -0.016067473217844963, -0.0026930510066449642, -0.006873083300888538, 0.04263128340244293, -0.005840270780026913, 0.008760405704379082, 0.011478688567876816, 0.016484634950757027, -0.00029584032017737627, -0.0026880046352744102, 0.011909307911992073, 0.024155035614967346, 0.020373662933707237, -0.023953184485435486, 0.012346655130386353, -0.0078049697913229465, 0.032134946435689926, 0.021692434325814247, -0.01399511843919754, 0.008679664693772793, -0.0078049697913229465, 0.0033726217225193977, -0.0120169622823596, 0.020333291962742805, 0.0219077430665493, 0.022149967029690742, 0.0048848348669707775, 0.01426425576210022, 0.0046190619468688965, -0.01980847492814064, -0.021921200677752495, 0.02153095230460167, -0.001444928697310388, -0.0028208910953253508, -0.007461820263415575, 0.012716718018054962, -0.010032077319920063, -0.013551042415201664, 0.0018990972312167287, -9.698390203993767e-05, 0.021463667973876, -0.01504475250840187, -0.01328190602362156, 0.022284535691142082, -0.01357122790068388, -0.0008322217618115246, 0.004861284978687763, 0.0024424174334853888, 0.007966452278196812, -0.002696415176615119, -0.01645772159099579, -0.004699802957475185, 0.011653627268970013, -0.01690179668366909, -0.004161529242992401, -0.003084981581196189, 0.018032172694802284, 0.029874194413423538, -0.001403717091307044, 0.02011798322200775, -0.022284535691142082, 0.03409964591264725, -0.012649433687329292, -0.04386931285262108, 0.004373474512249231, -0.001274195034056902, 0.02132909931242466, 0.013779808767139912, 0.0018217203905805945, -0.00749546242877841, -0.016040559858083725, 0.03025098703801632, 0.006213698070496321, -0.01906834915280342, 0.015233147889375687, 0.0010370181407779455, -0.0029638700652867556, -0.013517400249838829, 0.006681323517113924, 0.007710772100836039, -0.003100120695307851, -0.02687331847846508, 0.006405458319932222, 0.01818019710481167, 0.024262690916657448, -0.0035593353677541018, 0.03237716853618622, -0.0039226701483130455, -0.010489610023796558, -0.010186831466853619, 0.013308819383382797, 0.03423421457409859, 0.0009991707047447562, -0.021490581333637238, 7.5103384915564675e-06, -0.0015349213499575853, -0.0004291471850592643, -0.11583651602268219, -0.03878262639045715, 0.01602710224688053, 0.015004381537437439, 0.008309601806104183, -0.0027384678833186626, 0.020575515925884247, 0.0175477247685194, -0.017466984689235687, 0.025541091337800026, 0.006671230774372816, -0.034530263394117355, -0.005524034611880779, -0.009265037253499031, 0.0026829584967345, -0.021988485008478165, -0.008572010323405266, -0.04050510376691818, -0.0028545332606881857, 0.02481442131102085, 0.003926034551113844, -0.020333291962742805, 0.008659479208290577, -0.008356700651347637, 0.0319734625518322, -0.031354449689388275, -0.02224416472017765, 0.028878388926386833, 0.0071523129008710384, 0.011572886258363724, 0.016915254294872284, -0.02295737713575363, 0.023482194170355797, -0.02656381204724312, 0.00897571537643671, 0.002750242594629526, -0.000210368336411193, -0.009628372266888618, 0.006597218103706837, -0.016847969964146614, -0.014277712441980839, 0.0020319835748523474, 0.031354449689388275, -0.03159667178988457, 0.01003880612552166, -0.017466984689235687, -0.005783079192042351, 0.0053053610026836395, 0.008148119784891605, -0.005877276882529259, -0.0342072993516922, -0.011566158384084702, -0.03224259987473488, 0.018947238102555275, 0.02200194075703621, -0.018059086054563522, -0.009339050389826298, 0.036145083606243134, -0.022903550416231155, -0.003862114390358329, 0.013820179738104343, -0.0038217438850551844, -0.019727734848856926, -0.011478688567876816, 0.04198535531759262, -0.02220379374921322, 0.02443763054907322, 0.0005971475038677454, 0.007616573944687843, -0.002319623716175556, -0.010355042293667793, 0.005301996599882841, -0.016175126656889915, 0.000947866472415626, -0.029282094910740852, -0.0005546743050217628, 0.01208424661308527, -0.020198723301291466, 0.0034954154398292303, -0.01485635619610548, -0.035983603447675705, 0.003868842963129282, -0.005436565261334181, -0.043519437313079834, 0.006963917054235935, 0.009217938408255577, 0.01696908101439476, -0.003451680764555931, -0.0026509982999414206, -0.003885663812980056, -0.03165049850940704, 0.007892439141869545, 0.014291169121861458, -0.004410481080412865, 0.0003221232327632606, 0.013207892887294292, -0.007185955066233873, -0.00791262462735176, 0.028070978820323944, 0.025460349395871162, -0.029147526249289513, -0.028851475566625595, -0.03592977672815323, -0.0027906130999326706, -0.004676253534853458, -0.0031253520864993334, 0.022943919524550438, -0.020198723301291466, 0.039267074316740036, -0.009500532411038876, -0.010583808645606041, -0.01083275955170393, -0.012225543148815632, 0.014614133164286613, 0.010873130522668362, -0.006324716843664646, -0.005668696016073227, -0.03617199882864952, 0.03342680260539055, 0.000255049264524132, 0.026375414803624153, 0.0027334215119481087, -0.011424860917031765, 0.0063381739892065525, -0.0005298632895573974, 0.0018738656071946025, -0.0204544048756361, 0.025097016245126724, -0.017265131697058678, 0.026348501443862915, -0.030681606382131577, 0.002011798322200775, -0.0004983237595297396, -0.025568004697561264, 0.01517932116985321, 0.03700632229447365, -0.02088502235710621, -0.02237873338162899, -0.008491269312798977, 0.002750242594629526, -0.01083275955170393, -0.009709113277494907, -0.016888340935111046, -0.0005391148151829839, 0.02305157482624054, -0.006799070630222559, -0.002097585704177618, -0.01079911831766367, -0.0046089692041277885, 0.013187707401812077, 0.008659479208290577, -0.028420856222510338, 0.01238702517002821, 0.019512424245476723, 0.0007212027558125556, -0.0063718161545693874, -0.02231144905090332, -0.018530074506998062, 0.004111065994948149, -0.011626713909208775, -0.030008763074874878, -0.026442699134349823, 0.014250798150897026, 0.0011867254506796598, 0.0022859815508127213, -0.008323058485984802, 0.0009058138821274042, 0.013059867545962334, -0.030331727117300034, -0.017493898048996925, 0.024329975247383118, -0.01379326544702053, -0.01994304358959198, 0.005958017893135548, 0.011216280050575733, -0.0024609204847365618, 0.02474713698029518, 0.02893221564590931, 0.020373662933707237, -0.01370579656213522, -0.020642800256609917, 0.021073419600725174, 0.009392878040671349, -0.03450334817171097, 0.0004915953613817692, -0.009049728512763977, 0.01605401560664177, 0.006620767526328564, -0.0074550919234752655, 0.007508919574320316, 0.0032666490878909826, 0.001957970904186368, 0.013409745879471302, 0.008847875520586967, -0.0006942891050130129, -0.003919306211173534, 0.006418914999812841, 0.03178506717085838, 0.024329975247383118, -0.015663767233490944, 0.00650638435035944, 0.015946360304951668, 0.00579653587192297, -0.00041064401739276946, -0.02220379374921322, -0.02376478724181652, -0.012656162492930889, 0.03547224402427673, -0.006550119258463383, -0.03318458050489426, 0.005493756849318743, 0.01115572452545166, 0.02416849322617054, 0.030412469059228897, 0.016955625265836716, 0.014318082481622696, 0.01046269666403532, 0.004201899748295546, 0.004901655483990908, -0.024922076612710953, -0.022149967029690742, 0.011175910010933876, 0.004191807005554438, -0.004746901802718639, -0.009655286557972431, -0.03011641837656498, 0.013833636417984962, 3.7663394323317334e-05, 0.014237341471016407, -0.00953417457640171, 0.00030803558183833957, 0.026658009737730026, -0.006590489763766527, -0.03498779609799385, -0.05331601947546005, -0.013120424002408981, 0.001963017275556922, -0.022809352725744247, 0.0017359330086037517, -0.0018065813928842545, -0.02173280343413353, 0.06712274253368378, 0.026012081652879715, -0.016013644635677338, 0.0006320512038655579, -0.00898917205631733, 0.01643080823123455, -0.0011000970844179392, 0.0056754243560135365, 0.0005164064350537956, -0.010186831466853619, 0.004238906316459179, -0.02088502235710621, 0.015663767233490944, -0.01795143075287342, -0.018435876816511154, 0.0010563622927293181, 0.017493898048996925, 0.029793454334139824, -0.00884114671498537, -0.0114585030823946, 0.023576391860842705, -0.01039541233330965, 0.0014979150146245956, -0.001147196046076715, -0.027963323518633842, 0.001209433889016509, 0.0193374864757061, 0.010112819261848927, -0.008558553643524647, -0.038621146231889725, 0.0031556300818920135, 0.03813669830560684, -0.04255054146051407, -0.00939960591495037, 0.00028469637618400156, -0.017399700358510017, -0.01927020214498043, -0.0041884430684149265, 0.014277712441980839, 0.05899480730295181, -0.016888340935111046, 0.03574138134717941, -0.029524317011237144, 0.0024440994020551443, -0.017426613718271255, -0.028986044228076935, -0.014587219804525375, -0.011256651021540165, -0.03393816202878952]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x32fe36fd0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x330a7ac90>, model='text-embedding-ada-002', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create embeddings using OpenAI\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "def create_embeddings_openai(model='text-embedding-ada-002') -> OpenAIEmbeddings:\n",
    "\n",
    "    # Initialize the OpenAIEmbeddings class\n",
    "    embeddings = OpenAIEmbeddings(model=model)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "#####\n",
    "\n",
    "def test_create_embeddings_vertexai():\n",
    "    text = 'What is my benefit for acupuncture?'\n",
    "    embeddings = create_embeddings_openai()\n",
    "    vector = embeddings.embed_query(text)\n",
    "    print(vector)\n",
    "    return embeddings\n",
    "\n",
    "test_create_embeddings_vertexai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings using Vertex AI\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/text_embedding/google_vertex_ai_palm/\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "\n",
    "def create_embeddings_vertexai(model=\"text-embedding-004\") -> VertexAIEmbeddings:\n",
    "\n",
    "    # Initialize the VertexAIEmbeddings class\n",
    "    embeddings = VertexAIEmbeddings(model_name=model)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "#####\n",
    "\n",
    "def test_create_embeddings_vertexai():\n",
    "    text = 'What is a DUR reject?'\n",
    "    embeddings = create_embeddings_vertexai()\n",
    "    vector = embeddings.embed_query(text)\n",
    "    print(vector)\n",
    "    return embeddings\n",
    "\n",
    "test_create_embeddings_vertexai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "# Remove empty chunks \n",
    "\n",
    "def remove_empty_chunks(chunks_start: list) -> list:\n",
    "    \n",
    "    start = len(chunks_start)\n",
    "    # print(f'start - {start} chunks')\n",
    "    \n",
    "    # Remove empty chunks\n",
    "    chunks_end = [chunk for chunk in chunks_start if chunk.page_content.strip()]\n",
    "\n",
    "    end = len(chunks_end)\n",
    "    # print(f'end - {end} chunks')\n",
    "\n",
    "    return chunks_end   \n",
    "\n",
    "#####\n",
    "\n",
    "from langchain.schema import Document\n",
    "\n",
    "def test_remove_empty_chunks():\n",
    "    docs = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "\n",
    "    # Added a test doc\n",
    "    doc = Document(\n",
    "        page_content='',\n",
    "        metadata=docs[0].metadata\n",
    "    )\n",
    "    docs.append(doc)\n",
    "    print(len(docs))\n",
    "\n",
    "    # Remove the empty doc (chunk)\n",
    "    docs = remove_empty_chunks(docs)\n",
    "    print(len(docs))\n",
    "\n",
    "test_remove_empty_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "615\n",
      "Medi-Cal\n",
      "Member Handbook\n",
      "Combined Evidence of Coverage\n",
      "and Disclosure Form                   \n",
      " \n",
      "CAHealthWellness.com\n",
      "For TTY, contact California Relay by dialing 711 and \n",
      "provide the Member Services number: 1-877-658-0305\n"
     ]
    }
   ],
   "source": [
    "# Create a text splitter using recursive character text splitter\n",
    "\n",
    "# https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def chunk_docs_recursive(documents: list, chunk_size=500, chunk_overlap=50) -> list:\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "\n",
    "    chunks_start = text_splitter.split_documents(documents)\n",
    "\n",
    "    chunks_end = remove_empty_chunks(chunks_start=chunks_start)\n",
    "\n",
    "    return chunks_end\n",
    "\n",
    "#####\n",
    "\n",
    "def test_chunk_docs_recursive(): \n",
    "    docs = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "    chunks = chunk_docs_recursive(documents=docs)\n",
    "    print(len(chunks))\n",
    "    print(chunks[0].page_content)\n",
    "\n",
    "test_chunk_docs_recursive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 744, which is longer than the specified 500\n",
      "Created a chunk of size 796, which is longer than the specified 500\n",
      "Created a chunk of size 653, which is longer than the specified 500\n",
      "Created a chunk of size 1349, which is longer than the specified 500\n",
      "Created a chunk of size 742, which is longer than the specified 500\n",
      "Created a chunk of size 565, which is longer than the specified 500\n",
      "Created a chunk of size 580, which is longer than the specified 500\n",
      "Created a chunk of size 750, which is longer than the specified 500\n",
      "Created a chunk of size 506, which is longer than the specified 500\n",
      "Created a chunk of size 570, which is longer than the specified 500\n",
      "Created a chunk of size 541, which is longer than the specified 500\n",
      "Created a chunk of size 1038, which is longer than the specified 500\n",
      "Created a chunk of size 577, which is longer than the specified 500\n",
      "Created a chunk of size 587, which is longer than the specified 500\n",
      "Created a chunk of size 605, which is longer than the specified 500\n",
      "Created a chunk of size 1156, which is longer than the specified 500\n",
      "Created a chunk of size 946, which is longer than the specified 500\n",
      "Created a chunk of size 527, which is longer than the specified 500\n",
      "Created a chunk of size 546, which is longer than the specified 500\n",
      "Created a chunk of size 527, which is longer than the specified 500\n",
      "Created a chunk of size 673, which is longer than the specified 500\n",
      "Created a chunk of size 612, which is longer than the specified 500\n",
      "Created a chunk of size 1319, which is longer than the specified 500\n",
      "Created a chunk of size 1242, which is longer than the specified 500\n",
      "Created a chunk of size 1155, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630\n",
      "Medi-Cal\n",
      "Member Handbook\n",
      "Combined Evidence of Coverage\n",
      "and Disclosure Form                   \n",
      " \n",
      "CAHealthWellness.com\n",
      "For TTY, contact California Relay by dialing 711 and \n",
      "provide the Member Services number: 1-877-658-0305\n"
     ]
    }
   ],
   "source": [
    "# Create a text splitter using NLTK\n",
    "\n",
    "# https://python.langchain.com/docs/how_to/split_by_token/\n",
    "\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "\n",
    "def chunk_docs_nltk(documents: list, chunk_size=500, chunk_overlap=50) -> list:\n",
    "\n",
    "    text_splitter = NLTKTextSplitter(\n",
    "    chunk_size=chunk_size, \n",
    "    chunk_overlap=chunk_overlap)\n",
    "\n",
    "    chunks_start = text_splitter.split_documents(documents)\n",
    "\n",
    "    chunks_end = remove_empty_chunks(chunks_start=chunks_start)\n",
    "\n",
    "    return chunks_end\n",
    "\n",
    "#####\n",
    "\n",
    "def test_chunk_docs_nltk(): \n",
    "    docs = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "    chunks = chunk_docs_nltk(documents=docs)\n",
    "    print(len(chunks))\n",
    "    print(chunks[0].page_content)\n",
    "\n",
    "test_chunk_docs_nltk()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252\n",
      "Medi-Cal\n",
      "Member Handbook\n",
      "Combined Evidence of Coverage\n",
      "and Disclosure Form                   \n",
      " \n",
      "CAHealthWellness.com\n",
      "For TTY, contact California Relay by dialing 711 and \n",
      "provide the Member Services number: 1-877-658-0305\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a text splitter semantic chunking \n",
    "\n",
    "# https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/semantic-chunker/\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "def chunk_docs_semantic(documents: list, ) -> list:\n",
    "\n",
    "    # TODO - Use embeddings parameter\n",
    "    text_splitter = SemanticChunker(create_embeddings_openai(), breakpoint_threshold_type=\"percentile\")\n",
    "\n",
    "    chunks_start = text_splitter.split_documents(documents)\n",
    "\n",
    "    # Remove empty chunks\n",
    "    chunks_end = remove_empty_chunks(chunks_start)\n",
    "\n",
    "    return chunks_end\n",
    "\n",
    "#####\n",
    "\n",
    "def test_chunk_docs_semantic():\n",
    "    docs = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "    chunks = chunk_docs_semantic(docs)\n",
    "    print(len(chunks))\n",
    "    print(chunks[0].page_content)\n",
    "\n",
    "test_chunk_docs_semantic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "615\n",
      "test\n"
     ]
    }
   ],
   "source": [
    "# Create a Qdrant vector store\n",
    "\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "def create_qdrant_vector_store(location: str, collection_name: str, vector_size: int, embeddings: Embeddings, documents: list) -> QdrantVectorStore:\n",
    "\n",
    "    # Initialize the Qdrant client\n",
    "    qdrant_client = QdrantClient(location=location)\n",
    "\n",
    "    # Create a collection in Qdrant\n",
    "    qdrant_client.create_collection(collection_name=collection_name, vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE))\n",
    "\n",
    "    # Initialize QdrantVectorStore with the Qdrant client\n",
    "    qdrant_vector_store = QdrantVectorStore(client=qdrant_client, collection_name=collection_name, embedding=embeddings)\n",
    "    \n",
    "    qdrant_vector_store.add_documents(documents)\n",
    "    \n",
    "    return qdrant_vector_store\n",
    "\n",
    "#####\n",
    "\n",
    "def test_create_qdrant_vector_store():\n",
    "    embeddings = create_embeddings_openai()\n",
    "    docs = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "    print(len(docs))\n",
    "    chunks = chunk_docs_recursive(docs)\n",
    "    print(len(chunks))\n",
    "    vector_store = create_qdrant_vector_store(\":memory:\", \"test\", 1536, embeddings, chunks)\n",
    "    print(vector_store.collection_name)\n",
    "\n",
    "test_create_qdrant_vector_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QDRANT\n",
      "page_content='Acupuncture \n",
      " \n",
      "We will cover up to two outpatient acupuncture services in any calendar month.  Additional \n",
      "services may be covered if they are determined to be medically necessary.  You must receive \n",
      "prior authorization to receive more than two acupuncture services in a calendar month.   \n",
      " \n",
      "There is no frequency limit if you are getting acupuncture services through the Early and \n",
      "Periodic Screening, Diagnosis, & Treatment program,    \n",
      " \n",
      "Allergy Services' metadata={'source': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'file_path': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'page': 57, 'total_pages': 134, 'format': 'PDF 1.5', 'title': '', 'author': 'PTN Consulting', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word 2013', 'producer': 'Microsoft Word 2013', 'creationDate': \"D:20170421101839-07'00'\", 'modDate': \"D:20170421103401-07'00'\", 'trapped': '', '_id': '02947cd1536945538bdf045ce004aba8', '_collection_name': 'test'}\n"
     ]
    }
   ],
   "source": [
    "# Create a Qdrant retriever\n",
    "\n",
    "# TODO - Add reference \n",
    "\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "\n",
    "def create_retriever_qdrant(vector_store: QdrantVectorStore) -> BaseRetriever:\n",
    "\n",
    "    retriever = vector_store.as_retriever()\n",
    "\n",
    "    return retriever\n",
    "\n",
    "#####\n",
    "\n",
    "def test_create_retriever_qdrant(text: str = None):\n",
    "    embeddings = create_embeddings_openai()\n",
    "    docs = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "    chunks = chunk_docs_recursive(docs)\n",
    "    vector_store = create_qdrant_vector_store(\":memory:\", \"test\", 1536, embeddings, chunks)\n",
    "    retriever = create_retriever_qdrant(vector_store)\n",
    "    if text:\n",
    "        docs = retriever.invoke(text)\n",
    "        print(docs[0])\n",
    "\n",
    "print('\\nQDRANT')\n",
    "test_create_retriever_qdrant('What is my benefit for acupuncture?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Vertex AI retriever\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/retrievers/google_vertex_ai_search/\n",
    "\n",
    "from langchain_google_community import VertexAISearchRetriever\n",
    "\n",
    "def create_retriever_vertexai() -> VertexAISearchRetriever:\n",
    "\n",
    "    retriever = VertexAISearchRetriever(\n",
    "        project_id=os.environ['PROJECT_ID'],\n",
    "        location_id=os.environ['LOCATION_ID'],\n",
    "        data_store_id=os.environ['DATA_STORE_ID'],\n",
    "        max_documents=3,\n",
    "    )\n",
    "\n",
    "    return retriever\n",
    "\n",
    "#####\n",
    "\n",
    "def test_create_retriever_vertexai(text: str = None):\n",
    "    retriever = create_retriever_vertexai()\n",
    "    if text:\n",
    "        docs = retriever.invoke(text)\n",
    "        print(docs[0])\n",
    "\n",
    "print('\\nVERTEX AI')\n",
    "test_create_retriever_vertexai('What is a DUR reject?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='\\n    You are a helpful conversational agent for the State of California.\\n    Your expertise is fully understanding the California Health & Wellness health  plan. \\n    You need to answer questions posed by the member, who is trying to get answers about their health plan.  \\n    Your goal is to provide a helpful and detailed response, in at least 2-3 sentences. \\n\\n    You will be analyzing the health plan documents to derive a good answer, based on the following information:\\n    1. The question asked.\\n    2. The provided context, which comes from various documents of the pharmacy manuals repository. You will need to answer the question based on the provided context.\\n\\n    The output MUST BE A VALID JSON. This requires the following:\\n        - Ensure that the JSON structure includes curly braces at the beginning and end of the object.\\n        - Use double quotes for all keys and string values.\\n        - Ensure that keys and values are separated by a colon.\\n        - Separate multiple key-value pairs with commas.\\n        - Avoid trailing commas after the last key-value pair.\\n        - Avoid ticks \"`\"\" and triple ticks \"```\"\" in the response.\\n        - Special characters in strings should be escaped using backslashes (e.g., use \\\\\" for double quotes within strings).\\n        - Explain your reasoning for the answer.\\n\\n    You need to provide the response in the following JSON format:\\n        {{\\n        answer: The answer to the question. The answer should be clear, helpful and neither too long nor too short,\\n        context_used: Summarize, in 50 words or less, the relevant information used to generate the answer,\\n        confidence_score: A Number between 0 and 100 indicating how confident you are in the answer correctness,\\n        answer_confidence_reasoning: A short summary on what information is missing to make the answer to the question completely correct\\n        }}\\n\\n    Now it\\'s your turn!\\n\\n    {question}\\n\\n    {context}\\n\\n    '\n"
     ]
    }
   ],
   "source": [
    "# Create a prompt template\n",
    "\n",
    "# https://python.langchain.com/v0.1/docs/modules/model_io/prompts/quick_start/#chatprompttemplate\n",
    "# https://python.langchain.com/v0.2/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def create_chat_prompt_template(prompt: str = None) -> ChatPromptTemplate:\n",
    "    \n",
    "    template = '''\n",
    "    You are a helpful conversational agent for the State of California.\n",
    "    Your expertise is fully understanding the California Health & Wellness health  plan. \n",
    "    You need to answer questions posed by the member, who is trying to get answers about their health plan.  \n",
    "    Your goal is to provide a helpful and detailed response, in at least 2-3 sentences. \n",
    "\n",
    "    You will be analyzing the health plan documents to derive a good answer, based on the following information:\n",
    "    1. The question asked.\n",
    "    2. The provided context, which comes from various documents of the pharmacy manuals repository. You will need to answer the question based on the provided context.\n",
    "\n",
    "    The output MUST BE A VALID JSON. This requires the following:\n",
    "        - Ensure that the JSON structure includes curly braces at the beginning and end of the object.\n",
    "        - Use double quotes for all keys and string values.\n",
    "        - Ensure that keys and values are separated by a colon.\n",
    "        - Separate multiple key-value pairs with commas.\n",
    "        - Avoid trailing commas after the last key-value pair.\n",
    "        - Avoid ticks \"`\"\" and triple ticks \"```\"\" in the response.\n",
    "        - Special characters in strings should be escaped using backslashes (e.g., use \\\\\" for double quotes within strings).\n",
    "        - Explain your reasoning for the answer.\n",
    "\n",
    "    You need to provide the response in the following JSON format:\n",
    "        {{\n",
    "        answer: The answer to the question. The answer should be clear, helpful and neither too long nor too short,\n",
    "        context_used: Summarize, in 50 words or less, the relevant information used to generate the answer,\n",
    "        confidence_score: A Number between 0 and 100 indicating how confident you are in the answer correctness,\n",
    "        answer_confidence_reasoning: A short summary on what information is missing to make the answer to the question completely correct\n",
    "        }}\n",
    "\n",
    "    Now it's your turn!\n",
    "\n",
    "    {question}\n",
    "\n",
    "    {context}\n",
    "\n",
    "    '''\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    return prompt\n",
    "\n",
    "#####\n",
    "\n",
    "def test_create_chat_prompt_template():\n",
    "    prompt = create_chat_prompt_template()\n",
    "    print(prompt)\n",
    "\n",
    "test_create_chat_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "QDRANT\n",
      "{'response': AIMessage(content='{\\n\"answer\": \"The California Health & Wellness plan covers up to two outpatient acupuncture services per calendar month.  If you need more than two services, you will need to get prior authorization.  There is no frequency limit if you are getting acupuncture services through the Early and Periodic Screening, Diagnosis, & Treatment program.\",\\n\"context_used\": \"The California Health & Wellness plan covers up to two outpatient acupuncture services in any calendar month. Additional services may be covered if they are determined to be medically necessary. You must receive prior authorization to receive more than two acupuncture services in a calendar month. There is no frequency limit if you are getting acupuncture services through the Early and Periodic Screening, Diagnosis, & Treatment program.\",\\n\"confidence_score\": 95,\\n\"answer_confidence_reasoning\": \"The document does not specify what constitutes \\\\\"medically necessary\\\\\" for acupuncture services.  It also does not specify what the process is for obtaining prior authorization.\"\\n}', response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': [{'category': 'HARM_CATEGORY_SEXUALLY_EXPLICIT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HATE_SPEECH', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_HARASSMENT', 'probability': 'NEGLIGIBLE', 'blocked': False}, {'category': 'HARM_CATEGORY_DANGEROUS_CONTENT', 'probability': 'NEGLIGIBLE', 'blocked': False}]}, id='run-caa19ca8-9e5e-4eec-ab46-ba44a3f00dbe-0', usage_metadata={'input_tokens': 1703, 'output_tokens': 198, 'total_tokens': 1901}), 'context': [Document(metadata={'source': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'file_path': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'page': 57, 'total_pages': 134, 'format': 'PDF 1.5', 'title': '', 'author': 'PTN Consulting', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word 2013', 'producer': 'Microsoft Word 2013', 'creationDate': \"D:20170421101839-07'00'\", 'modDate': \"D:20170421103401-07'00'\", 'trapped': '', '_id': '4d0f9ff10fad43ddb69bff0f2b2fed14', '_collection_name': 'test'}, page_content='Acupuncture \\n \\nWe will cover up to two outpatient acupuncture services in any calendar month.  Additional \\nservices may be covered if they are determined to be medically necessary.  You must receive \\nprior authorization to receive more than two acupuncture services in a calendar month.   \\n \\nThere is no frequency limit if you are getting acupuncture services through the Early and \\nPeriodic Screening, Diagnosis, & Treatment program,    \\n \\nAllergy Services'), Document(metadata={'source': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'file_path': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'page': 77, 'total_pages': 134, 'format': 'PDF 1.5', 'title': '', 'author': 'PTN Consulting', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word 2013', 'producer': 'Microsoft Word 2013', 'creationDate': \"D:20170421101839-07'00'\", 'modDate': \"D:20170421103401-07'00'\", 'trapped': '', '_id': '9d79ba9630f347f3beb06af870ae639e', '_collection_name': 'test'}, page_content='Wellness to get these services.'), Document(metadata={'source': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'file_path': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'page': 57, 'total_pages': 134, 'format': 'PDF 1.5', 'title': '', 'author': 'PTN Consulting', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word 2013', 'producer': 'Microsoft Word 2013', 'creationDate': \"D:20170421101839-07'00'\", 'modDate': \"D:20170421103401-07'00'\", 'trapped': '', '_id': 'e13cb96378264be1ae8d84c858904975', '_collection_name': 'test'}, page_content='for specific details. \\n \\nAbortion  \\n \\nAbortion services are covered by California Health & Wellness as a physician service. It is \\ncovered without California Health & Wellness approval if done as an outpatient service or in the \\nevent of an emergency. You do need California Health & Wellness approval if done as an \\ninpatient service. You may go to any provider of your choice for abortion services, at any time for \\nany reason, regardless of network affiliation.  \\n \\nAcupuncture'), Document(metadata={'source': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'file_path': 'docs/CHW_EOC_04-21-2017_ENG.pdf', 'page': 8, 'total_pages': 134, 'format': 'PDF 1.5', 'title': '', 'author': 'PTN Consulting', 'subject': '', 'keywords': '', 'creator': 'Microsoft Word 2013', 'producer': 'Microsoft Word 2013', 'creationDate': \"D:20170421101839-07'00'\", 'modDate': \"D:20170421103401-07'00'\", 'trapped': '', '_id': '70e5526cea0f4896aae86c49f285c324', '_collection_name': 'test'}, page_content='Health & Wellness to make an appointment for a checkup.  This will give the PCP \\na chance to do an initial exam and help find any health problems or steps you may \\nneed to take to stay healthy.   \\n \\nTip #3 \\nTalk to your PCP about any problems before you need care \\nDo not wait until you are sick to talk with your PCP.  Seeing your doctor for \\nregular checkups helps you find health problems early.  This can help keep you in \\ngood health and out of the emergency room. \\n \\nTip #4')]}\n"
     ]
    }
   ],
   "source": [
    "# Create a Langchain chain..\n",
    "\n",
    "# https://python.langchain.com/docs/integrations/llms/google_ai/\n",
    "# https://python.langchain.com/docs/integrations/chat/google_generative_ai/\n",
    "# https://ai.google.dev/gemini-api/docs/safety-settings \n",
    "\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from operator import itemgetter\n",
    "\n",
    "def create_chain (model_name: str, prompt: ChatPromptTemplate, retriever: BaseRetriever):\n",
    "\n",
    "    if \"gemini\" in model_name.lower():\n",
    "        llm = ChatGoogleGenerativeAI(\n",
    "            model=model_name,\n",
    "            temperature=0,\n",
    "            safety_settings={\n",
    "                    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "                },\n",
    "            )\n",
    "    else:\n",
    "        print(\"Unsuported model name\")\n",
    "        \n",
    "    chain = (\n",
    "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")} \n",
    "        | RunnablePassthrough.assign(context=itemgetter(\"context\")) \n",
    "        | {\"response\": prompt | llm, \"context\": itemgetter(\"context\")}\n",
    "        )\n",
    "\n",
    "    return chain\n",
    "\n",
    "#####\n",
    "\n",
    "def test_create_chain_qdrant():\n",
    "    embeddings = create_embeddings_openai()\n",
    "    docs = process_file('docs/CHW_EOC_04-21-2017_ENG.pdf')\n",
    "    chunks = chunk_docs_recursive(docs)\n",
    "    vector_store = create_qdrant_vector_store(\":memory:\", \"test\", 1536, embeddings, chunks)\n",
    "    retriever = create_retriever_qdrant(vector_store)\n",
    "    chat_prompt_template = create_chat_prompt_template()\n",
    "    chain = create_chain('gemini-1.5-flash', chat_prompt_template, retriever)\n",
    "    result = chain.invoke({'question' : 'What is my benefit for acupuncture?'})\n",
    "    print(result)\n",
    "\n",
    "print('\\nQDRANT')\n",
    "test_create_chain_qdrant()\n",
    "\n",
    "# def test_create_chain_vertexai():\n",
    "#     retreiver = create_retriever_vertexai()\n",
    "#     chat_prompt_template = create_chat_prompt_template()\n",
    "#     chain = create_chain('gemini-1.5-flash', chat_prompt_template, retreiver)\n",
    "#     result = chain.invoke({'question' : 'What is my benefit for acupuncture?'})\n",
    "#     print(result)\n",
    "\n",
    "# print('\\nVERTEX AI')\n",
    "# test_create_chain_vertexai()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate answeers from a chain usin a list of questions\n",
    "\n",
    "def generate_answers_contexts(chain, questions: list):\n",
    "    \n",
    "    answers = []\n",
    "    contexts = []\n",
    "\n",
    "    # Loop over the list of questions and call the chain to get the answer and context\n",
    "    for question in questions:\n",
    "        print(question)\n",
    "\n",
    "        # Call the chain to get answers and contexts\n",
    "        response = chain.invoke({\"question\" : question})\n",
    "        print(response)\n",
    "        \n",
    "        # Capture the answer and context \n",
    "        answers.append(response[\"response\"].content)\n",
    "        contexts.append([context.page_content for context in response[\"context\"]])\n",
    "\n",
    "    return answers, contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "# Run a Ragas evaluation \n",
    "\n",
    "from datasets import Dataset\n",
    "from pandas import DataFrame\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "\n",
    "def run_ragas_evaluation(chain, \n",
    "                         questions: list, \n",
    "                         groundtruths: list, \n",
    "                         eval_metrics: list = [answer_correctness, \n",
    "                                               answer_relevancy, \n",
    "                                               context_recall, \n",
    "                                               context_precision, \n",
    "                                               faithfulness]):\n",
    "\n",
    "  answers, contexts = []\n",
    "  answers, contexts = generate_answers_contexts(chain, questions)\n",
    "\n",
    "  # Create the input dataset \n",
    "  input_dataset = Dataset.from_dict({\n",
    "  \"question\" : questions,         # From the dataframe\n",
    "  \"answer\" : answers,             # From the chain\n",
    "  \"contexts\" : contexts,          # From the chain\n",
    "  \"ground_truth\" : groundtruths   # From the dataframe\n",
    "  })\n",
    "\n",
    "  # Run the Ragas evaluation using the input dataset and eval metrics\n",
    "  ragas_results = evaluate(input_dataset, eval_metrics)\n",
    "  ragas_results_df = ragas_results.to_pandas()\n",
    "  \n",
    "  return ragas_results, ragas_results_df\n",
    "  \n",
    "  #####\n",
    "\n",
    "def test_run_ragas_evaluation():\n",
    "  print(\"test\")    \n",
    "\n",
    "test_run_ragas_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1728070414.346501 1513933 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ya29.a0AcM612xQhk7xeEHmuVvA83EtnvSUXrP4mcDHVSzDpzlSEBEGpZ_CJNDbSbXtCX95YhXfMtAX5nMolrBMbTrYeTjIv2ZI6Yi53Hm0r_VRBXholcmmS7j-eHYz1ds0vbboGq2hnlv6Y8KLAkioJNM07vfZaFrxB8zpAYRklKzbFAaCgYKATYSARESFQHGX2Miqjq7c4jyUvOtqGqcinGFPQ0177\n",
      "https://us-discoveryengine.googleapis.com/v1alpha/projects/virtual-assist-poc-434617/locations/us/collections/default_collection/dataStores/virtual-assist-poc-docs_1727390753315/servingConfigs/default_search:search\n",
      "{'results': [{'chunk': {'name': 'projects/695172254544/locations/us/collections/default_collection/dataStores/virtual-assist-poc-docs_1727390753315/branches/0/documents/8fc366005ca1959f1d792465b111e426/chunks/c2', 'id': 'c2', 'content': 'Lost Prescription  04\\n\\nTherapy Change  05\\n\\n\\n\\nFor claims greater than a 30-day supply, the pharmacy must submit individual claims, each of 30-day supplies (up to 6 claims for a total of 180-day supply).\\n\\n\\n\\nIf the pharmacy submits the claim with the Clarification Code and the claim still rejects, check the Submitted Drug Utilization Review again. There may be more than one issue with the claim. For example, the member could have an Ingredient Duplication and a High Dose Alert on the same claim. Do NOT create an override for the pharmacy.\\n\\n\\n\\nIf a DUR Rejects Document: \\n\\nPharmacist first and last name\\n\\nDrug name on current claim\\n\\nDrug name from claim that is causing the reject  including date of service.\\n\\n\\n\\nTherapeutic Duplication: This reject indicates that the current medication duplicates the therapy of another medication. IT MAY NOT BE OVERRIDDEN BY THE PHARMACY OR HELP DESK.\\n\\nTHE MEMBER/PROVIDER MAY REQUEST A PRIOR AUTHORIZATION IF THE DOCTOR FEELS THE THERAPY IS CLINICALLY APPROPRIATE.\\n\\n\\n\\nHigh-Dose: A High-Dose DUR reject indicates that the member may be taking greater than a safe dose of a specific medication, type of medication, or medication ingredient. You may not override a High-Dose reject, unless specifically indicated within the plan benefits.  \\n\\n\\n\\nMED ### EXEEDED; TOTAL MED XXXMG: This rejection indicates that the member has exceeded the cumulative allowable Opioid daily dosage (MED). For possible continued coverage on this product, Prior Authorization is required.\\n\\n\\n\\nTotal APAP>4g;Verify Dose; Call HelpDesk: This rejection occurs when the members daily dose of Acetaminophen (APAP) exceeds 4 grams per day.\\n\\nFor PDP### & MPD### plans, refer to KB0031977 Opioid Index Card.\\n\\nAll other plans should notify the caller that a prior authorization/coverage determination is required for high-dose therapy.\\n\\n\\n\\nDrug-Drug Interaction: This rejection occurs when the drug being filled may interact with another drug that the member has taken in the recent past. The drug that may cause the conflict is listed in the rejection.  \\n\\n\\n\\nIf the rejection note shows onset = RAPID; Documentation = ESTABLISHED, overrides are not allowed, including Medical Necessity. \\n\\nAdvise the pharmacy calling in that these rejections cannot be overridden and do not provide any override codes.\\n\\nThe pharmacist can dispense at their own discretion; however, the plan will not process the claim for payment.\\n\\nDo not transfer to the Prior Authorization Dept. or the Consulting RPh line.\\n\\nDo not refer callers to their health plan.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nBack to Main Menu\\n\\n\\n\\nSoft Rejects', 'documentMetadata': {'uri': 'gs://virtual-assist-poc/docs/Google - Reject 88_DUR and DUR PPS 04 01 24.docx', 'title': 'Google - Reject 88_DUR and DUR PPS 04 01 24'}, 'relevanceScore': 0.8295246362686157}}, {'chunk': {'name': 'projects/695172254544/locations/us/collections/default_collection/dataStores/virtual-assist-poc-docs_1727390753315/branches/0/documents/8fc366005ca1959f1d792465b111e426/chunks/c6', 'id': 'c6', 'content': 'PG  Pregnancy: Utilization conflicts may exist with pregnant women\\n\\nLR  Under Use: Potential underuse of the drug exists\\n\\nPA  Drug/Age: Potential drug conflicts  exist based on the patients age\\n\\nLD  Low Dose: The dosage of the drug exceeds an established minimum\\n\\n\\n\\nBack to Main Menu\\n\\n\\n\\nProfessional Service / Intervention Code\\n\\nThe Professional Service code denotes what professional intervention the pharmacy took to resolve the DUR reject. The pharmacy should use the appropriate code based on that intervention.\\n\\n\\n\\nThe codes in red are those that are typically allowed to override a DUR rejection.\\n\\n\\n\\nCode/ Description:\\n\\nM0  Prescriber Consulted: The prescriber was consulted to determine whether to dispense the drug.\\n\\nP0  Patient Consulted: The patient was consulted to determine whether to dispense the drug\\n\\nPE  Patient Education: The patient was educated on the appropriate use of this drug in combination with the other drug\\n\\nR0  Pharmacist Consulted: The pharmacist used professional judgment.\\n\\nTH  Therapeutic Product Interchange: The drug was changed to another therapeutically similar drug\\n\\nDE  Dosing Evaluation/ Determination: A determination was made as it relates to the drugs dosing\\n\\n\\n\\nBack to Main Menu\\n\\n\\n\\nResult / Outcome Code\\n\\nThe Result Code denotes whether the drug was dispensed, and if so, how. The pharmacy should use the code corresponding to the result of their action.\\n\\n\\n\\nThe codes in red are those that are typically allowed to override a DUR rejection.\\n\\n\\n\\nReason:\\n\\n1A  Filled as is, false positive: The drug is filled, no interaction\\n\\n1B  Filled as is: The drug was filled\\n\\n1C  Filled with different dose: The drug was filled with a different dose\\n\\n1D  Filled, different directions for use: The drug was filled with different directions\\n\\n1F  Filled with different quantity: The drug was filled with a different quantity\\n\\n1G  Filled with prescriber approval: The drug was filled based on prescriber consultation, and approval\\n\\n3A  Recommendation accepted: The drug is not filled, DUR recommendation accepted\\n\\n3C  Discontinued other drug: The drug is filled, the other drug has been discontinued\\n\\n3D  Regimen changed: The members medication regimen has been changed\\n\\n3E  Therapy change: The members medication therapy has been changed\\n\\n\\n\\nBack to Main Menu\\n\\n\\n\\nCommunicating Codes\\n\\nWhen communicating to a pharmacy which codes are allowed, you should communicate the requirement  not just the code. This way, the pharmacy understands that they must take a specific action instead of just using the code to bypass the claim rejection.', 'documentMetadata': {'uri': 'gs://virtual-assist-poc/docs/Google - Reject 88_DUR and DUR PPS 04 01 24.docx', 'title': 'Google - Reject 88_DUR and DUR PPS 04 01 24'}, 'relevanceScore': 0.8319490551948547}}, {'chunk': {'name': 'projects/695172254544/locations/us/collections/default_collection/dataStores/virtual-assist-poc-docs_1727390753315/branches/0/documents/8fc366005ca1959f1d792465b111e426/chunks/c1', 'id': 'c1', 'content': 'OptumRx Job Aid\\n\\nKB0032238\\n\\nTitle: Reject 88_DUR and DUR PPS \\n\\nApproved By: Kia Williams\\n\\nPrepared By: Kia Williams\\n\\nEffective Date:  10/01/2015\\n\\n\\n\\nLast Revision Date: 04/01/2024\\n\\nAnnual Review Date: 04/01/2025\\n\\nKeywords: Reject, 88, DUR, Hold, Opioid, Limit, PPS, Code\\n\\nScope: A DUR reject indicates possible concerns with the therapeutic utilization of a particular drug. It may be a drug interaction, excessive dosing, or duplication in drug therapy.\\n\\nApplies To: ORx PBM Specialist\\n\\n\\n\\nMain Menu\\n\\nOverview\\n\\nHard Rejects\\n\\nSoft Rejects\\n\\nOpioid Soft Rejects\\n\\nPPS Code Explanation\\n\\nReason for Service Code (Conflict Code)\\n\\nProfessional Service Code (Intervention Code)\\n\\nResult Code (Outcome Code)\\n\\nCommunicating Codes\\n\\n\\n\\nQ&A\\n\\n\\n\\n\\n\\nOverview\\n\\nA DUR reject indicates possible concerns with the therapeutic utilization of a particular drug. It may be a drug interaction, excessive dosing, or duplication in drug therapy. \\n\\n\\xa0\\n\\nThe Consulting Pharmacist cannot release the hold or bypass the special review.\\xa0\\n\\n\\xa0\\n\\nCSAs can contact the Consulting Pharmacist for clinical issues such as the following:\\n\\nDiscuss clinically related issues such as doses\\n\\nMay discuss drug interaction, adverse reactions\\n\\nAssist with identifying alternative medication names\\n\\nNote: Refer to KB0086499: When to Engage a Pharmacist Interactive Tool to determine if its appropriate to call a Consulting Pharmacist.\\n\\n\\n\\nDUR/PPS codes are a combination of codes that allow a pharmacy to bypass certain Reject 88 DUR rejections at point of sale. These codes indicate that the pharmacy took specific action to resolve the DUR rejection. DUR/PPS codes are only allowed to be used for a SOFT DUR rejection.\\n\\n\\t\\n\\n\\tDO\\xa0THIS\\xa0FIRST \\t\\n\\nAccess the Drug Utilization Review Information on the bottom of the Claim Detail tab. \\n\\nReview the first line of this section to determine the RESPONSE\\xa0(1) and DUR\\xa0REASON (2) and select the appropriate link below.\\n\\n\\n\\nReason Type (1)\\n\\nHard Reject\\n\\nOr \\n\\nSoft Reject\\n\\nDUR Reason (2)\\n\\nIngredient Duplication)\\n\\nTherapeutic Duplication\\n\\nHigh-Dose\\n\\nDrug-Drug\\n\\n\\n\\n\\n\\n\\n\\nBack to Main Menu\\n\\n\\n\\nHard Rejects\\n\\nIngredient Duplication: This rejection is usually caused by a pharmacy attempting to refill a drug earlier than the plan allows.\\n\\n\\n\\nCommon overrides that are allowed for this rejection include those listed below. However, you must refer to the plan specific information (Advocate Central/CPD) to determine if these or any other overrides are allowed.\\n\\nIf an override is allowed, enter the override per existing procedures.\\n\\nIf an override is not allowed, notify the pharmacy.\\n\\nIf plan benefits indicate that the pharmacy should submit a clarification code to override, have the pharmacy resubmit the claim with one of the applicable codes below:\\n\\nVacation Supply  03', 'documentMetadata': {'uri': 'gs://virtual-assist-poc/docs/Google - Reject 88_DUR and DUR PPS 04 01 24.docx', 'title': 'Google - Reject 88_DUR and DUR PPS 04 01 24'}, 'relevanceScore': 0.816208004951477}}, {'chunk': {'name': 'projects/695172254544/locations/us/collections/default_collection/dataStores/virtual-assist-poc-docs_1727390753315/branches/0/documents/8fc366005ca1959f1d792465b111e426/chunks/c7', 'id': 'c7', 'content': 'To override this DUR rejection, this plan requires that you Consult with the prescriber (M0), patient (P0) or pharmacist (R0). You may then either fill the drug as-is (1B), or with prescriber approval (1G). You should use the applicable codes associated with these requirements.\\n\\n\\n\\nThe codes in red are those that are typically allowed to override a DUR rejection.\\n\\n\\n\\nConflict Code: ER  Overuse / Intervention Code: M0  Prescriber Consulted / Outcome Code: 1A  Filled as is, false positive\\n\\nConflict Code: TD  Therapeutic Duplication / Intervention Code: P0  Patient Consulted / Outcome Code: 1B  Filled as is\\n\\nConflict Code: DD  Drug-Drug Interaction / Intervention Code: PE  Patient Education / Outcome Code: 1C  Filled with different dose\\n\\nConflict Code: HD  High Dose / Intervention Code: R0  Pharmacist Consulted / Outcome Code: 1D  Filled, different directions for use\\n\\nConflict Code: PG  Pregnancy / Intervention Code: TH  Therapeutic Product Interchange / Outcome Code: 1F  Filled with different quantity\\n\\nConflict Code: LR  Under Use / Intervention Code: DE  Dosing Evaluation / Outcome Code: 1G  Filled with prescriber approval\\n\\nConflict Code: PA  Drug/Age / Outcome Code: 3A  Recommendation accepted\\n\\nConflict Code: LD  Low Dose\\n\\nOutcome Code: 3C  Discontinued other drug\\n\\nOutcome Code: 3D  Regimen changed\\n\\nOutcome Code: 3E  Therapy changed\\n\\n\\n\\nBack to Main Menu\\n\\n\\n\\nQ&A\\n\\nThe pharmacy doesnt know how to use PPS codes.\\n\\nThe pharmacy should contact their corporate office, or software support. We cannot advise the pharmacy how to use their specific point-of-sale or pharmacy processing system.\\n\\n\\n\\nThe pharmacy is using PPS Codes, but the claim is still rejecting.\\n\\nFirst make sure that it is a SOFT DUR rejection. If it is, the pharmacy may be using a PPS code combination that is not allowed by the plan. PPS codes are not allowed for Hard DUR rejects.\\n\\n\\n\\nCan I tell a pharmacy to use any code that works?\\n\\nNo. PPS codes indicate that the pharmacy took specific action to resolve the DUR rejection. They may use any code that will bypass the DUR rejection as long as they have taken the action specified by the code they use.\\n\\n\\n\\nAre PPS codes the same as Submission Clarification Codes (SCC)?', 'documentMetadata': {'uri': 'gs://virtual-assist-poc/docs/Google - Reject 88_DUR and DUR PPS 04 01 24.docx', 'title': 'Google - Reject 88_DUR and DUR PPS 04 01 24'}, 'relevanceScore': 0.7734622359275818}}, {'chunk': {'name': 'projects/695172254544/locations/us/collections/default_collection/dataStores/virtual-assist-poc-docs_1727390753315/branches/0/documents/8fc366005ca1959f1d792465b111e426/chunks/c3', 'id': 'c3', 'content': 'Ingredient Duplication: This rejection is usually caused by a pharmacy attempting to refill a drug earlier than the plan allows.\\n\\n\\n\\nCommon overrides that are allowed for this rejection include those listed below. However, you must refer to the plan specific information (Advocate Central/CPD) to determine if these or any other overrides are allowed.\\n\\nIf an override is allowed, enter the override per existing procedures.\\n\\nIf an override is not allowed, notify the pharmacy.\\n\\nIf plan benefits indicate that the pharmacy should submit a clarification code to override, have the pharmacy resubmit the claim with one of the applicable codes below:\\n\\nVacation Supply  03\\n\\nLost Prescription  04\\n\\nTherapy Change  05\\n\\n\\n\\nFor claims greater than a 30-day supply, the pharmacy must submit individual claims, each of 30-day supplies (up to 6 claims for a total of 180-day supply).\\n\\n\\n\\nIf the pharmacy submits the claim with the Clarification Code and the claim still rejects, check the Submitted Drug Utilization Review again. There may be more than one issue with the claim. For example, the member could have an Ingredient Duplication and a High Dose Alert on the same claim. Do NOT create an override for the pharmacy.\\n\\n\\n\\nTherapeutic Duplication: This reject indicates that the current medication duplicates the therapy of another medication. It may be overridden by the pharmacy by using DUR PPS codes. Do NOT create an override for the pharmacy.\\n\\n\\n\\nThe pharmacy must submit the claim by using one of the below Submission Clarification Code combinations. Please note, not all combinations will be allowed for all plans. \\n\\n\\n\\nReason: TD  Therapeutic Duplication \\n\\nProfessional Codes: M0  Prescriber Consulted / Result Codes: 1A  Filled as is, false positive\\n\\nProfessional Codes: P0  Patient Consulted / Results Codes: 1G  Filled with prescriber approval\\n\\nProfessional Codes: PE  Patient Education/ Instructions / Results Codes: 3A  Recommendation accepted\\n\\nProfessional Codes: TH  Therapeutic product interchange\\n\\nResults Codes: 3C  Discontinued another drug\\n\\nResults Codes: 3D  Regimen Changed\\n\\nResults Codes: 3E  Therapy Changed\\n\\nHigh-Dose: There are various high-dose programs in effect that may be used by clients.\\n\\n\\n\\n\\n\\nMED ### EXEEDED; TOTAL MED XXXMG: This rejection occurs when a members cumulative Morphine Equivalent Dose (MED) has exceeded the designated threshold.\\n\\n\\n\\nACTION: The pharmacy may use PPS Codes to override the rejection. \\n\\n\\n\\nReason: HD (High Dose Alert) / Professional: M0 (Prescriber Consulted) / Result: 1G (Filled, Prescriber Approval)', 'documentMetadata': {'uri': 'gs://virtual-assist-poc/docs/Google - Reject 88_DUR and DUR PPS 04 01 24.docx', 'title': 'Google - Reject 88_DUR and DUR PPS 04 01 24'}, 'relevanceScore': 0.7897593975067139}}], 'totalSize': 13, 'attributionToken': '6gHw6QoMCI-GgbgGEK_k59ABEiQ2NmZmZjI5MS0wMDAwLTJkZjYtOTUwNi01ODI0MjljZjg0Y2MiB0dFTkVSSUMqqAHExrEwqvizLcfGsTCorrcwlZLFMLe3jC2uxIot6IKxLZCktDCgibMtlt6oL46-nRXej5oi64KxLYCymiLR5rUvq8SKLa34sy2Z3qgvy5q0MLSSrjDbmrQw1LKdFduPmiKY1rctzua1L6OAlyK3kq4wwvCeFeftiC2Q97Iw-fazLaWutzDOmrQw5O2ILd6atDDFy_MX_PazLYOymiKNpLQwo4mzLZvWty0wAQ', 'nextPageToken': 'wYjRDOmNWOyQjM4UTL2ATN50iNmRmMtADMwATLwkjMmZmZ2YDJaIApRabnQYAuQ--jIwgE1EgC', 'guidedSearchResult': {}, 'summary': {}}\n"
     ]
    }
   ],
   "source": [
    "# Query Vertex AI Search datastore using HTTP Post\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import google.auth\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "credentials, project_id = google.auth.default()\n",
    "credentials.refresh(Request())\n",
    "access_token = credentials.token\n",
    "print(access_token)\n",
    "\n",
    "def query_chunks(query, n=5):\n",
    "    \n",
    "  if LOCATION_ID == 'us':\n",
    "    api_endpoint = 'us-discoveryengine.googleapis.com'\n",
    "  else:\n",
    "    api_endpoint = 'discoveryengine.googleapis.com'\n",
    "\n",
    "  url = f\"https://{api_endpoint}/v1alpha/projects/{PROJECT_ID}/locations/{LOCATION_ID}/collections/default_collection/dataStores/{DATA_STORE_ID}/servingConfigs/default_search:search\"\n",
    "  print(url)\n",
    "  \n",
    "  headers = {\n",
    "      \"Authorization\": f\"Bearer {access_token}\",\n",
    "      \"Content-Type\": \"application/json\",\n",
    "  }\n",
    "  \n",
    "  post_data = {\n",
    "      \"servingConfig\": f\"projects/{PROJECT_ID}/locations/{LOCATION_ID}/collections/default_collection/dataStores/{DATA_STORE_ID}/servingConfigs/default_search\",\n",
    "      \"pageSize\": n,\n",
    "      \"query\": query,\n",
    "      \"contentSearchSpec\": {\"searchResultMode\": \"CHUNKS\"},\n",
    "  }\n",
    "  \n",
    "  response = requests.post(url, headers=headers, json=post_data)\n",
    "\n",
    "  if response.status_code != 200:\n",
    "    print(\n",
    "        f\"Error retrieving search results: {response.status_code} -\"\n",
    "        f\" {response.text}\"\n",
    "    )\n",
    "\n",
    "  return response.json()\n",
    "\n",
    "#####\n",
    "\n",
    "test = query_chunks('What is my benefit for acupuncture?')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RAG chain using Vertex AI vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RAG chain using Vertex AI Agent Builder datastore\n",
    "\n",
    "retreiver = create_retriever_vertexai()\n",
    "chat_prompt_template = create_chat_prompt_template()\n",
    "chain = create_chain('gemini-1.5-flash', chat_prompt_template, retreiver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the chain \n",
    "\n",
    "questions = [\"What is a DUR reject?\",\n",
    "\"What is the difference between hard and soft rejects?\",\n",
    "\"What is TrOOP\",\n",
    "\"What is the clarification code for lost prescription\"]\n",
    "\n",
    "for question in questions:\n",
    "    print(question)\n",
    "    result = chain.invoke({\"question\" : question})\n",
    "    print(result)\n",
    "    print(result[\"response\"].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate answers from the golden Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Golden Q&A\n",
    "testset_df = pd.read_excel('golden_qa/KN Virtual Assist POC_08.09.24 1_mk.xlsx', 'Consolidated Golden QnA')\n",
    "\n",
    "questions = testset_df[\"Question\"].values.tolist()\n",
    "questions = [str(question) for question in questions]\n",
    "\n",
    "answers, contexts = generate_answers_contexts(chain, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create customer testset and evaluate using Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the golden Q&A and get questions and ground truths\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "testset_df = pd.read_excel('golden_qa/KN Virtual Assist POC_08.09.24 1_mk.xlsx', 'Consolidated Golden QnA')\n",
    "\n",
    "questions = testset_df[\"Question\"].values.tolist()\n",
    "questions = [str(question) for question in questions]\n",
    "\n",
    "groundtruths = testset_df[\"Answer\"].values.tolist()\n",
    "groundtruths = [str(ground_truth) for ground_truth in groundtruths]\n",
    "\n",
    "print(\"Writing customer_testset.csv\")\n",
    "testset_df.to_csv(\"testsets/customer_testset.csv\")\n",
    "testset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the customer testset using Ragas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Get the questions and groundtruths from the dataframe\n",
    "testset_df = pd.read_csv(\"testsets/customer_testset.csv\")\n",
    "\n",
    "questions = testset_df[\"Question\"].values.tolist()\n",
    "questions = [str(question) for question in questions]\n",
    "\n",
    "groundtruths = testset_df[\"Answer\"].values.tolist()\n",
    "groundtruths = [str(ground_truth) for ground_truth in groundtruths]  \n",
    "\n",
    "# Specify the eval metrics\n",
    "eval_metrics = [answer_correctness, answer_relevancy, context_precision, context_recall, faithfulness]\n",
    "\n",
    "# Run the Ragas evaluation and show the results\n",
    "ragas_results, ragas_results_df = run_ragas_evaluation(chain, questions, groundtruths, eval_metrics)\n",
    "\n",
    "# Write the results to disk\n",
    "print(\"Writing customer_testset_ragas_results.csv\")\n",
    "ragas_results_df.to_csv(\"ragas/customer_testset_ragas_results.csv\")\n",
    "\n",
    "# Show the resutls\n",
    "ragas_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create synthetic testset and evaluate using Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MaxRetriesExceeded' from 'ragas.exceptions' (/opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages/ragas/exceptions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatOpenAI, OpenAIEmbeddings\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtestset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevolutions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple, reasoning, multi_context\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtestset\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TestsetGenerator\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Load the docs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages/ragas/testset/evolutions.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MaxRetriesExceeded\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRagasLLM\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_load\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_loader\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MaxRetriesExceeded' from 'ragas.exceptions' (/opt/anaconda3/envs/aie4-demo/lib/python3.11/site-packages/ragas/exceptions.py)"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "from ragas.testset.evolutions import simple, reasoning, multi_context\n",
    "from ragas.testset.generator import TestsetGenerator\n",
    "\n",
    "# Load the docs\n",
    "documents = []\n",
    "\n",
    "paths = ['docs/CHW_EOC_04-21-2017_ENG.pdf']\n",
    "\n",
    "for path in paths:\n",
    "    documents.extend(process_file(path=path))\n",
    "\n",
    "# Chunk the docs \n",
    "# chunks = chunk_docs_nltk(documents, 1500, 150)\n",
    "chunks = chunk_docs_semantic(documents)\n",
    "\n",
    "# Set up the parameters for generating the testset\n",
    "generator_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "critic_llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embeddings = OpenAIEmbeddings()\n",
    "generator = TestsetGenerator.from_langchain(generator_llm, critic_llm, embeddings)\n",
    "distributions = {simple: 0.5, multi_context: 0.4, reasoning: 0.1}\n",
    "\n",
    "# Generate the testset and save to disk \n",
    "testset = generator.generate_with_langchain_docs(documents=chunks, test_size=50, distributions=distributions)\n",
    "testset_df = testset.to_pandas()\n",
    "\n",
    "print(\"Writing synthetic_testset.csv\")\n",
    "testset_df.to_csv(\"testsets/synthetic_testset.csv\")\n",
    "testset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the synthetic testset using Ragas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Run the Ragas evaluation and show the results\n",
    "# Get the questions and groundtruths from the dataframe\n",
    "testset_df = pd.read_csv(\"testsets/synthetic_testset.csv\")\n",
    "\n",
    "questions = testset_df[\"question\"].values.tolist()\n",
    "questions = [str(question) for question in questions]\n",
    "\n",
    "groundtruths = testset_df[\"ground_truth\"].values.tolist()\n",
    "groundtruths = [str(ground_truth) for ground_truth in groundtruths]  \n",
    "\n",
    "# Specify the eval metrics\n",
    "eval_metrics = [answer_correctness, answer_relevancy, context_precision, context_recall, faithfulness]\n",
    "\n",
    "# Run the Ragas evaluation and show the results\n",
    "ragas_results, ragas_results_df = run_ragas_evaluation(chain, questions, groundtruths, eval_metrics)\n",
    "\n",
    "# Write the results to disk\n",
    "print(\"Writing synthetic_testset_ragas_results.csv\")\n",
    "ragas_results_df.to_csv(\"ragas/synthetic_testset_ragas_results.csv\")\n",
    "\n",
    "# Show the resutls\n",
    "ragas_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aie4-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
